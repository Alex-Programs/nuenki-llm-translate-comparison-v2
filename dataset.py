SENTENCES_LIST = {
    "phrases_internet": [
        "ratio + L + cope + seethe",  # from poking around the internet
        "Python enumerate() Function",
        "Top 1% Commenter",
        "Eggs US – Price – Chart",
    ],
    "short_sentence": [
        "This isn’t what I ordered.",  # wrote myself
        "The best translator is a hybrid translator",  # internet
        "Will this be available to download on GitHub?",
        "It doesn't matter now.",  # wrote myself
    ],
    "medium_sentence": [
        "And a few things I think would be cool, but aren't core to the idea:",  # from r foxhole
        "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.",
        "The risk was calculated, but the variables were bollocks.",  # added swearing to a somewhat common meme-phrase
        "The Nuenki browser extension finds sentences in the websites you visit.",  # nuenki front page!
    ],
    "long_sentence": [
        "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.",  # r vtolvr. I felt that it was sufficiently meandering
        "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.",  # wrote myself to be as irritating to translate as possible. The only thing it's missing is nested subordinate clauses
        "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.",  # nuenki blog post
        "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples",  # "attention is all you need" :P
    ],
    "paragraph": [
        "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.",  # from https://nuenki.app/blog/the_best_translator_is_a_hybrid_translator, except I replaced "GPT-4.1" with "redacted" because I felt mentioning specific models would do little to help the "model-lineage-bias" issue!
        "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.",  # wrote it myself. Loosely inspired by "Yes, Minister"
        "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.",  # Highly inspired by "Yes, Minister"
        "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.",  # my own; attempting to do it more like a child's story
    ],
}
