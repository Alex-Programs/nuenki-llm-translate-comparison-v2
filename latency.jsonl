{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.2971374988555908, "logged_at": 1746211472.9286861}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0765833854675293, "logged_at": 1746211783.370438}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.3685879707336426, "logged_at": 1746211787.1185544}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.069000244140625, "logged_at": 1746211790.7366006}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.8569920063018799, "logged_at": 1746211794.2054276}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.0772123336791992, "logged_at": 1746211797.0984743}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.9451971054077148, "logged_at": 1746211800.2987897}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.0933082103729248, "logged_at": 1746211803.3948822}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.792569875717163, "logged_at": 1746211807.5711036}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.4829010963439941, "logged_at": 1746212487.0174334}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0717182159423828, "logged_at": 1746212520.2708032}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.3436522483825684, "logged_at": 1746212523.9945402}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.1823527812957764, "logged_at": 1746212528.507721}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.8673708438873291, "logged_at": 1746212532.539399}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.4229133129119873, "logged_at": 1746214641.5754607}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.805009365081787, "logged_at": 1746214645.8837957}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.7997024059295654, "logged_at": 1746214649.6672833}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.2835111618041992, "logged_at": 1746214736.2822955}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.1066174507141113, "logged_at": 1746214739.1520545}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.060647964477539, "logged_at": 1746214741.1559622}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.063253402709961, "logged_at": 1746214743.1563036}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 2.11576771736145, "logged_at": 1746214747.2124276}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.3861842155456543, "logged_at": 1746214753.8020198}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.657794713973999, "logged_at": 1746214756.362567}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.592878818511963, "logged_at": 1746214759.4215944}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.122992753982544, "logged_at": 1746214764.6260047}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.298855781555176, "logged_at": 1746214768.030071}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 3.1206953525543213, "logged_at": 1746214772.17649}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.0200612545013428, "logged_at": 1746214776.075655}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.3813912868499756, "logged_at": 1746216518.472969}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.043968915939331, "logged_at": 1746216519.5173886}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.8143436908721924, "logged_at": 1746216520.3324056}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.655975341796875, "logged_at": 1746216520.9888875}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.9782993793487549, "logged_at": 1746216521.967854}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.9143490791320801, "logged_at": 1746216522.8826344}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.4005987644195557, "logged_at": 1746216524.2837217}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 4.494946002960205, "logged_at": 1746216528.778989}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.0037288665771484, "logged_at": 1746216529.7831657}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.915215253829956, "logged_at": 1746216530.698729}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.9528858661651611, "logged_at": 1746216531.6520152}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.1788363456726074, "logged_at": 1746216532.8312678}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8996589183807373, "logged_at": 1746216533.731411}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.9251580238342285, "logged_at": 1746216534.6568978}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.1973156929016113, "logged_at": 1746216535.8546662}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8175129890441895, "logged_at": 1746216536.6725998}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.2242021560668945, "logged_at": 1746216537.8975108}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.037571907043457, "logged_at": 1746216538.9354959}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.1098737716674805, "logged_at": 1746216540.045844}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.2858030796051025, "logged_at": 1746216541.3320165}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8562989234924316, "logged_at": 1746216542.1886919}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.070509910583496, "logged_at": 1746216543.2594712}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.9394426345825195, "logged_at": 1746216546.642025}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.0253551006317139, "logged_at": 1746216547.6677976}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.0558159351348877, "logged_at": 1746216548.7242365}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.431997537612915, "logged_at": 1746216550.1566799}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.2980356216430664, "logged_at": 1746216553.9945736}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9829599857330322, "logged_at": 1746216554.9779897}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.7029383182525635, "logged_at": 1746216558.6113653}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.5949923992156982, "logged_at": 1746216560.2067733}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.2915356159210205, "logged_at": 1746216568.3308485}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.1842389106750488, "logged_at": 1746216569.5153747}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 4.083331108093262, "logged_at": 1746216580.6677268}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.9503273963928223, "logged_at": 1746216584.618583}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.6506834030151367, "logged_at": 1746216599.5800488}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 3.087787389755249, "logged_at": 1746216602.66815}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.478583812713623, "logged_at": 1746216611.4164348}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.655756950378418, "logged_at": 1746216613.0725446}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.1154472827911377, "logged_at": 1746216622.6395938}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.181455612182617, "logged_at": 1746216624.8213608}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8395907878875732, "logged_at": 1746216630.5218334}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7893872261047363, "logged_at": 1746216638.4830232}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.8291325569152832, "logged_at": 1746216644.7422893}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.7166414260864258, "logged_at": 1746216647.5856574}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.974576473236084, "logged_at": 1746216648.5607064}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7724394798278809, "logged_at": 1746216649.333541}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7487421035766602, "logged_at": 1746216650.0828693}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.5991764068603516, "logged_at": 1746216650.6823492}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8969020843505859, "logged_at": 1746216651.5795746}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.3460907936096191, "logged_at": 1746216652.9260325}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8586239814758301, "logged_at": 1746216656.5373297}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7872567176818848, "logged_at": 1746216657.3249426}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.3034148216247559, "logged_at": 1746216669.603194}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.1099107265472412, "logged_at": 1746216672.9619737}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.5199778079986572, "logged_at": 1746216676.8126874}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.586740493774414, "logged_at": 1746216685.6135652}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 5.736400365829468, "logged_at": 1746216701.874441}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.8205294609069824, "logged_at": 1746216718.0339384}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.3281970024108887, "logged_at": 1746216731.0148106}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.1499011516571045, "logged_at": 1746216746.9333465}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.912585973739624, "logged_at": 1746277713.5564468}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0142803192138672, "logged_at": 1746277723.0998485}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.6935594081878662, "logged_at": 1746277723.79379}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.7323369979858398, "logged_at": 1746277727.5507646}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7751405239105225, "logged_at": 1746277728.3264375}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.8030543327331543, "logged_at": 1746277729.1298897}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.839421272277832, "logged_at": 1746277729.9699075}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8233723640441895, "logged_at": 1746277730.7936037}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8534591197967529, "logged_at": 1746277731.6473641}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.05008864402771, "logged_at": 1746277742.3893907}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.9002816677093506, "logged_at": 1746277745.5591109}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.0070714950561523, "logged_at": 1746277746.5681455}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5343971252441406, "logged_at": 1746277754.4675303}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9011867046356201, "logged_at": 1746277758.5176008}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.2018327713012695, "logged_at": 1746277759.72112}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.3477964401245117, "logged_at": 1746277769.5929942}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.5867974758148193, "logged_at": 1746277780.454946}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.148885488510132, "logged_at": 1746277795.5391886}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 4.162233352661133, "logged_at": 1746277813.4324467}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.3942108154296875, "logged_at": 1746277823.0032916}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8508336544036865, "logged_at": 1746277833.5331154}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.5877823829650879, "logged_at": 1746277845.4788647}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7314450740814209, "logged_at": 1746277846.2114992}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.6590907573699951, "logged_at": 1746277849.277307}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6843874454498291, "logged_at": 1746277849.962255}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7290632724761963, "logged_at": 1746277850.6919188}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8601009845733643, "logged_at": 1746277851.5525465}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.602961540222168, "logged_at": 1746277858.992146}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8453369140625, "logged_at": 1746277859.8380811}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0336852073669434, "logged_at": 1746277860.8724906}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.7648942470550537, "logged_at": 1746277864.4469016}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.87939453125, "logged_at": 1746277865.3267195}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.8104362487792969, "logged_at": 1746277866.1384475}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.3756024837493896, "logged_at": 1746277869.5187416}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 0.8708932399749756, "logged_at": 1746277872.9482586}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.486497163772583, "logged_at": 1746277882.3401015}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 1.7144837379455566, "logged_at": 1746277901.9204688}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.3752329349517822, "logged_at": 1746277924.7518687}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.7635483741760254, "logged_at": 1746278452.5601234}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.7139694690704346, "logged_at": 1746278468.2195387}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.7973818778991699, "logged_at": 1746278477.3632388}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.8961849212646484, "logged_at": 1746278486.2346747}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.6577682495117188, "logged_at": 1746278486.893045}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.6710238456726074, "logged_at": 1746278490.6376822}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6046218872070312, "logged_at": 1746278491.2429078}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.6823492050170898, "logged_at": 1746278491.9257832}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7833187580108643, "logged_at": 1746278492.7096376}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.6023008823394775, "logged_at": 1746278493.3124573}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.3715956211090088, "logged_at": 1746278494.684624}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.7780966758728027, "logged_at": 1746278495.463282}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8651754856109619, "logged_at": 1746278498.982859}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.8070175647735596, "logged_at": 1746278499.7909703}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.0584626197814941, "logged_at": 1746278500.8500419}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9616904258728027, "logged_at": 1746278503.8701355}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 0.8783295154571533, "logged_at": 1746278505.7131383}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 0.959355354309082, "logged_at": 1746278516.0283897}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 1.9283511638641357, "logged_at": 1746278529.9825718}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.4718475341796875, "logged_at": 1746278541.5387573}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.2771389484405518, "logged_at": 1746278551.5328727}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.3733062744140625, "logged_at": 1746278562.22813}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.724318265914917, "logged_at": 1746278570.4358766}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 5.311007022857666, "logged_at": 1746278583.1205666}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.5785007476806641, "logged_at": 1746278583.7003646}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.0545153617858887, "logged_at": 1746278587.0253942}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7202768325805664, "logged_at": 1746278587.7461102}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.8940427303314209, "logged_at": 1746278588.6408472}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7398619651794434, "logged_at": 1746278596.4726262}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 2.530003070831299, "logged_at": 1746278606.4154243}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 2.417092800140381, "logged_at": 1746278608.8329391}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.4833898544311523, "logged_at": 1746278739.0213053}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.169285535812378, "logged_at": 1746278997.2284126}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 2.9056193828582764, "logged_at": 1746279000.134578}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.2424538135528564, "logged_at": 1746279001.3787124}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 16.179057121276855, "logged_at": 1746279021.0047805}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 5.212327241897583, "logged_at": 1746279028.4981906}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 2.776808023452759, "logged_at": 1746279039.3967817}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.8193531036376953, "logged_at": 1746279051.5667002}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 4.1032798290252686, "logged_at": 1746279078.848498}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 13.046830177307129, "logged_at": 1746279100.386233}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 5.354496717453003, "logged_at": 1746279113.8624418}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.4293689727783203, "logged_at": 1746279124.4153554}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.591954231262207, "logged_at": 1746279133.6408396}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 2.1518051624298096, "logged_at": 1746279135.8098454}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.0205388069152832, "logged_at": 1746279136.8310776}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7644402980804443, "logged_at": 1746279137.5960667}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.654280424118042, "logged_at": 1746279138.2506316}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 4.075302600860596, "logged_at": 1746279142.3270147}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 3.1775736808776855, "logged_at": 1746279145.5051758}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.4036660194396973, "logged_at": 1746279146.909524}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.2060351371765137, "logged_at": 1746279148.1161685}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.6892538070678711, "logged_at": 1746279152.9577658}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.2684106826782227, "logged_at": 1746279154.2267432}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.3304030895233154, "logged_at": 1746279163.1930838}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.9317634105682373, "logged_at": 1746279165.125596}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.0787336826324463, "logged_at": 1746279170.4831605}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 4.173696756362915, "logged_at": 1746279182.9465678}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 7.157452583312988, "logged_at": 1746279190.104731}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 6.467875003814697, "logged_at": 1746279206.3111153}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 3.6932578086853027, "logged_at": 1746279222.6736138}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 15.040959358215332, "logged_at": 1746279245.6897879}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 2.070071220397949, "logged_at": 1746283724.2336206}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.175955057144165, "logged_at": 1746283725.4099143}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.8909296989440918, "logged_at": 1746283726.3015213}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.0316641330718994, "logged_at": 1746283727.3336143}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.0542187690734863, "logged_at": 1746283728.3888805}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7480161190032959, "logged_at": 1746283729.1372}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.8571054935455322, "logged_at": 1746283732.6767051}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.795621395111084, "logged_at": 1746283733.472806}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.061798095703125, "logged_at": 1746283746.0226617}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.00972580909729, "logged_at": 1746283747.032764}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.8695633411407471, "logged_at": 1746283755.9421797}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0412404537200928, "logged_at": 1746283756.9836683}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.9193878173828125, "logged_at": 1746283758.90753}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.4444494247436523, "logged_at": 1746283760.3522675}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.2155468463897705, "logged_at": 1746283781.0847216}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0978171825408936, "logged_at": 1746283782.1830127}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.6580426692962646, "logged_at": 1746283790.7978466}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.7464275360107422, "logged_at": 1746283792.5445833}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 3.067359447479248, "logged_at": 1746283803.5165892}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.641279697418213, "logged_at": 1746283806.158396}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.1160080432891846, "logged_at": 1746283809.989143}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6352405548095703, "logged_at": 1746283810.6248844}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6694724559783936, "logged_at": 1746283818.7206528}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.6605515480041504, "logged_at": 1746283821.3464727}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1561996936798096, "logged_at": 1746283840.5091813}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0633544921875, "logged_at": 1746283848.7037826}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 0.9935872554779053, "logged_at": 1746283856.592645}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0642266273498535, "logged_at": 1746283877.0501266}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 4.446897745132446, "logged_at": 1746283889.5357313}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.245124101638794, "logged_at": 1746283899.841608}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.8255293369293213, "logged_at": 1746283908.5371046}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6745331287384033, "logged_at": 1746283909.2121637}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6902265548706055, "logged_at": 1746283909.9035938}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.8587236404418945, "logged_at": 1746283966.4683251}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.940014123916626, "logged_at": 1746283967.4114387}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0770068168640137, "logged_at": 1746283968.4889467}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.2864127159118652, "logged_at": 1746283969.7811353}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0443429946899414, "logged_at": 1746283992.241054}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.351135015487671, "logged_at": 1746284003.6049225}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.5818099975585938, "logged_at": 1746284013.8875709}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.3214025497436523, "logged_at": 1746284018.547091}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6012134552001953, "logged_at": 1746284020.017902}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7786316871643066, "logged_at": 1746284027.8114266}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.8379766941070557, "logged_at": 1746284029.6506267}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.3566136360168457, "logged_at": 1746284044.7556105}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.1680619716644287, "logged_at": 1746284053.671373}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 2.356259822845459, "logged_at": 1746284064.296307}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.8145720958709717, "logged_at": 1746284086.3877108}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 4.589008331298828, "logged_at": 1746284096.945929}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 16.36616086959839, "logged_at": 1746284121.3958037}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.46372652053833, "logged_at": 1746284127.9161167}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.8752973079681396, "logged_at": 1746284129.7114005}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6654727458953857, "logged_at": 1746284130.3790064}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 5.524034738540649, "logged_at": 1746284135.9035065}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.4114775657653809, "logged_at": 1746284155.2923415}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.9689235687255859, "logged_at": 1746284169.0619414}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 3.7981510162353516, "logged_at": 1746284179.9463186}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.7604129314422607, "logged_at": 1746284198.3348129}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 19.511823892593384, "logged_at": 1746284227.7621005}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 5.157696962356567, "logged_at": 1746284237.4419923}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 2.312882900238037, "logged_at": 1746297975.62049}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.3125414848327637, "logged_at": 1746297976.9333942}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.495391607284546, "logged_at": 1746298022.4502997}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0120179653167725, "logged_at": 1746298023.4627047}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.9893252849578857, "logged_at": 1746298024.4524994}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.9021763801574707, "logged_at": 1746298026.3551033}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.1807785034179688, "logged_at": 1746298054.4479587}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.9674625396728516, "logged_at": 1746298055.4158885}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.9967596530914307, "logged_at": 1746298057.4131866}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.3225440979003906, "logged_at": 1746298058.7362208}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.034609079360962, "logged_at": 1746298083.7639177}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.1503400802612305, "logged_at": 1746298084.9146457}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.0216078758239746, "logged_at": 1746298085.9369357}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.2222049236297607, "logged_at": 1746298087.159412}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.0013995170593262, "logged_at": 1746298088.161143}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.1140761375427246, "logged_at": 1746298089.2755451}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.997079610824585, "logged_at": 1746298090.2731328}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.177112340927124, "logged_at": 1746298091.4505544}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.0373897552490234, "logged_at": 1746298092.4884393}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.9966559410095215, "logged_at": 1746298093.4854004}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7779500484466553, "logged_at": 1746298094.263672}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7090482711791992, "logged_at": 1746298094.972956}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.3155553340911865, "logged_at": 1746298096.2889144}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.1829028129577637, "logged_at": 1746298097.4721782}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.22324800491333, "logged_at": 1746298129.1591585}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.3680500984191895, "logged_at": 1746298130.527745}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.1827867031097412, "logged_at": 1746298131.7111423}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.7459721565246582, "logged_at": 1746298133.4575589}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.993480920791626, "logged_at": 1746298163.1001453}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.9981772899627686, "logged_at": 1746298164.0989084}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.3902297019958496, "logged_at": 1746298165.4898522}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.1941030025482178, "logged_at": 1746298166.6845596}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 2.152752161026001, "logged_at": 1746298189.650929}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 3.718883752822876, "logged_at": 1746298193.3700778}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.8249561786651611, "logged_at": 1746298217.7707064}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.3200123310089111, "logged_at": 1746298219.0911214}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.4460086822509766, "logged_at": 1746298244.6782568}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.3853085041046143, "logged_at": 1746298246.0640323}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.5763866901397705, "logged_at": 1746298278.7417078}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.8818697929382324, "logged_at": 1746298280.6240394}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.6937017440795898, "logged_at": 1746298316.1307216}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.524998426437378, "logged_at": 1746298317.6560044}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.6675982475280762, "logged_at": 1746298347.6923943}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.6766724586486816, "logged_at": 1746298349.3695102}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.157897710800171, "logged_at": 1746298388.438237}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.5323400497436523, "logged_at": 1746298389.9710667}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.4646437168121338, "logged_at": 1746298437.2990732}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 2.8417325019836426, "logged_at": 1746298440.141598}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.5296313762664795, "logged_at": 1746298442.671837}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.9329729080200195, "logged_at": 1746298445.6050775}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 3.6563241481781006, "logged_at": 1746298491.1027546}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.163916826248169, "logged_at": 1746298493.2672558}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.781658172607422, "logged_at": 1746298533.9326882}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.188013792037964, "logged_at": 1746298536.1210825}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.9930009841918945, "logged_at": 1746298595.1210248}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.428231716156006, "logged_at": 1746298597.549741}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.426804304122925, "logged_at": 1746298625.8734324}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.171823501586914, "logged_at": 1746298628.045696}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 3.27384352684021, "logged_at": 1746298664.1139011}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.766407012939453, "logged_at": 1746298666.8807933}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.0463001728057861, "logged_at": 1746298737.744995}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6324577331542969, "logged_at": 1746298794.3541903}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7163650989532471, "logged_at": 1746298795.0712416}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.7504503726959229, "logged_at": 1746298818.4656682}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.7789974212646484, "logged_at": 1746298819.2452326}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6338682174682617, "logged_at": 1746298842.7760253}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7755212783813477, "logged_at": 1746298864.771493}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.381812334060669, "logged_at": 1746298866.1537755}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8562617301940918, "logged_at": 1746298867.0107887}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 5.312146186828613, "logged_at": 1746298893.4197402}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.8100476264953613, "logged_at": 1746298894.2304747}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.6715872287750244, "logged_at": 1746298894.9027948}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8296713829040527, "logged_at": 1746298924.580539}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.9327678680419922, "logged_at": 1746298925.5141392}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8408341407775879, "logged_at": 1746298954.5507233}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7636599540710449, "logged_at": 1746298978.9307406}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1772749423980713, "logged_at": 1746298980.1084352}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.9827625751495361, "logged_at": 1746299017.8091595}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5044667720794678, "logged_at": 1746299051.6385918}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 4.960722923278809, "logged_at": 1746299081.7680726}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.2163021564483643, "logged_at": 1746299108.4068193}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.017157793045044, "logged_at": 1746299138.9721382}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.3252437114715576, "logged_at": 1746299177.8132274}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.1108951568603516, "logged_at": 1746299212.0768821}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.151233673095703, "logged_at": 1746299270.8446577}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.8177294731140137, "logged_at": 1746299347.420337}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.7412934303283691, "logged_at": 1746299401.3186302}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.9627857208251953, "logged_at": 1746299441.4718769}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.4573721885681152, "logged_at": 1746299510.8516781}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.0989694595336914, "logged_at": 1746299554.9336545}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.0347075462341309, "logged_at": 1746299642.6262984}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.9735739231109619, "logged_at": 1746299682.287019}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.8516180515289307, "logged_at": 1746299703.171596}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.6331417560577393, "logged_at": 1746299725.2616265}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.0804784297943115, "logged_at": 1746299726.3427546}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7784457206726074, "logged_at": 1746299727.1219485}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7742681503295898, "logged_at": 1746299738.9358654}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7070186138153076, "logged_at": 1746299766.2802505}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7019038200378418, "logged_at": 1746299766.9827204}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7798902988433838, "logged_at": 1746299767.7629445}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.9921929836273193, "logged_at": 1746299768.7555497}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.87538743019104, "logged_at": 1746299769.6315293}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.063281536102295, "logged_at": 1746299795.1056898}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.9179954528808594, "logged_at": 1746299796.0241446}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8855819702148438, "logged_at": 1746299821.886059}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7869315147399902, "logged_at": 1746299845.9853983}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.9858150482177734, "logged_at": 1746299878.0259655}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0029263496398926, "logged_at": 1746299911.187298}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5801851749420166, "logged_at": 1746299912.7684588}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9132480621337891, "logged_at": 1746299945.254491}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.289494514465332, "logged_at": 1746299979.3987489}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 0.9401853084564209, "logged_at": 1746300006.0283265}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.196204423904419, "logged_at": 1746300033.889116}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.281299114227295, "logged_at": 1746300062.5434933}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.943415403366089, "logged_at": 1746300090.7635214}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.7201757431030273, "logged_at": 1746300139.1050448}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.9413857460021973, "logged_at": 1746300184.8953009}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.7562177181243896, "logged_at": 1746300219.9350066}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 3.088459014892578, "logged_at": 1746300267.6777806}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.202486276626587, "logged_at": 1746300307.4295096}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.965749979019165, "logged_at": 1746300368.999551}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6446301937103271, "logged_at": 1746300433.662373}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 4.094383478164673, "logged_at": 1746300443.23413}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.640758752822876, "logged_at": 1746300469.738534}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 2.5795648097991943, "logged_at": 1746300472.3187418}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7413904666900635, "logged_at": 1746300473.0605786}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6408901214599609, "logged_at": 1746300473.7021823}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7540552616119385, "logged_at": 1746300500.476672}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7635085582733154, "logged_at": 1746300501.2405758}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8713483810424805, "logged_at": 1746300526.0176091}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.666358232498169, "logged_at": 1746300555.0390346}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.7529599666595459, "logged_at": 1746300573.4340994}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.3174774646759033, "logged_at": 1746300601.0714946}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 2.4013619422912598, "logged_at": 1746300631.5543494}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 3.389629364013672, "logged_at": 1746300654.682045}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.9924685955047607, "logged_at": 1746300677.3616505}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.5340125560760498, "logged_at": 1746300701.8771722}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.3202002048492432, "logged_at": 1746300733.2444608}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.2181107997894287, "logged_at": 1746300764.56198}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 4.747503995895386, "logged_at": 1746300793.6680875}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.066340446472168, "logged_at": 1746300838.2975945}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 2.3562417030334473, "logged_at": 1746300873.8925726}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.9269824028015137, "logged_at": 1746300903.886142}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.6288118362426758, "logged_at": 1746300942.9324245}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 5.287922143936157, "logged_at": 1746300986.8512614}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 4.286499738693237, "logged_at": 1746301037.1809945}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 4.757099628448486, "logged_at": 1746301118.5717123}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 5.635262727737427, "logged_at": 1746301161.504968}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 7.219548940658569, "logged_at": 1746301205.7008858}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.7057256698608398, "logged_at": 1746302279.3985467}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.0031311511993408, "logged_at": 1746302280.4022498}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.9837353229522705, "logged_at": 1746302312.9171815}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.1484298706054688, "logged_at": 1746302314.0660174}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.013606071472168, "logged_at": 1746302315.0802667}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.8623197078704834, "logged_at": 1746302315.9430487}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.8054468631744385, "logged_at": 1746302350.839676}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.9381897449493408, "logged_at": 1746302351.778133}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.0952794551849365, "logged_at": 1746302352.8738444}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.5708470344543457, "logged_at": 1746302354.4450023}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.936887264251709, "logged_at": 1746302355.3822536}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.9919288158416748, "logged_at": 1746302356.3745604}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7213425636291504, "logged_at": 1746302357.0963938}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7431797981262207, "logged_at": 1746302357.8398213}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.0259513854980469, "logged_at": 1746302358.866175}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.1418890953063965, "logged_at": 1746302360.0084677}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.9860987663269043, "logged_at": 1746302360.9948914}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8931279182434082, "logged_at": 1746302361.888278}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8353359699249268, "logged_at": 1746302362.7239256}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.0791809558868408, "logged_at": 1746302363.8033702}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.0443525314331055, "logged_at": 1746302391.3356876}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.9524681568145752, "logged_at": 1746302392.2884731}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.7797515392303467, "logged_at": 1746302393.068885}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.8837881088256836, "logged_at": 1746302393.9530666}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.1829609870910645, "logged_at": 1746302395.1365955}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.9733998775482178, "logged_at": 1746302396.1103876}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.061908483505249, "logged_at": 1746302413.7604659}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0605485439300537, "logged_at": 1746302414.8212502}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.1393096446990967, "logged_at": 1746302439.1178463}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.9015052318572998, "logged_at": 1746302440.0196183}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.991241455078125, "logged_at": 1746302441.0112314}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.011681079864502, "logged_at": 1746302442.0233138}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1773467063903809, "logged_at": 1746302465.3225918}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1607823371887207, "logged_at": 1746302466.4836602}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.483780860900879, "logged_at": 1746302508.1312995}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.1241185665130615, "logged_at": 1746302509.2557752}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 2.0969464778900146, "logged_at": 1746302534.9201767}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.2825608253479004, "logged_at": 1746302536.2033055}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.164257287979126, "logged_at": 1746302556.7040334}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.2979555130004883, "logged_at": 1746302558.0031092}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.357257604598999, "logged_at": 1746302595.5736167}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.2306931018829346, "logged_at": 1746302596.80474}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.6637864112854004, "logged_at": 1746302626.4976106}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.480231523513794, "logged_at": 1746302627.9781637}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.6131856441497803, "logged_at": 1746302655.6857471}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.056624174118042, "logged_at": 1746302656.7426908}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.6303069591522217, "logged_at": 1746302702.2705548}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.3694565296173096, "logged_at": 1746302703.642465}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.6212375164031982, "logged_at": 1746302729.2506847}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.5706145763397217, "logged_at": 1746302731.8220162}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.8283777236938477, "logged_at": 1746302778.885419}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.7250328063964844, "logged_at": 1746302780.6108096}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.8589363098144531, "logged_at": 1746302807.6523721}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.144440174102783, "logged_at": 1746302809.7972906}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.6973512172698975, "logged_at": 1746302848.155671}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.8463685512542725, "logged_at": 1746302850.002983}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.082651376724243, "logged_at": 1746302886.7368872}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.4489119052886963, "logged_at": 1746302889.1867194}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.045053958892822, "logged_at": 1746302928.5211778}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.545274019241333, "logged_at": 1746302931.0667458}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8141770362854004, "logged_at": 1746303005.0275621}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6675088405609131, "logged_at": 1746303046.7106571}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7663455009460449, "logged_at": 1746303068.5932124}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.2518270015716553, "logged_at": 1746303091.0781596}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.8724780082702637, "logged_at": 1746303091.9512317}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.8008584976196289, "logged_at": 1746303115.2563255}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6105916500091553, "logged_at": 1746303144.5974867}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7252011299133301, "logged_at": 1746303161.5224926}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8217813968658447, "logged_at": 1746303162.3464975}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7679107189178467, "logged_at": 1746303186.3341353}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7523050308227539, "logged_at": 1746303204.2339425}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.769129753112793, "logged_at": 1746303205.0034795}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.1186532974243164, "logged_at": 1746303238.9082594}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0079069137573242, "logged_at": 1746303239.9183686}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.7452547550201416, "logged_at": 1746303267.559062}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.8524706363677979, "logged_at": 1746303293.430816}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.9663803577423096, "logged_at": 1746303316.2332017}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.092477560043335, "logged_at": 1746303359.5014808}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.9779894351959229, "logged_at": 1746303385.7687442}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.354477882385254, "logged_at": 1746303413.5335333}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.0864009857177734, "logged_at": 1746303441.164755}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.0398147106170654, "logged_at": 1746303468.526466}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.4572436809539795, "logged_at": 1746303528.5782783}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.02470064163208, "logged_at": 1746303560.120735}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.6758553981781006, "logged_at": 1746303598.9846096}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.7366564273834229, "logged_at": 1746303646.6693075}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.7952184677124023, "logged_at": 1746303684.5665286}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 3.551130771636963, "logged_at": 1746303716.7141757}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.2689208984375, "logged_at": 1746303766.6910756}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.3181400299072266, "logged_at": 1746303807.2792826}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8126816749572754, "logged_at": 1746303889.119393}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7470035552978516, "logged_at": 1746303925.3149104}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7803421020507812, "logged_at": 1746303926.096143}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.8372888565063477, "logged_at": 1746303956.648037}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.0603656768798828, "logged_at": 1746303957.7091835}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6632213592529297, "logged_at": 1746303958.3734877}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6541845798492432, "logged_at": 1746303986.357271}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.8046810626983643, "logged_at": 1746304011.7717218}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.899486780166626, "logged_at": 1746304012.6734686}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7301619052886963, "logged_at": 1746304013.404645}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.8677859306335449, "logged_at": 1746304014.2734377}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.7275106906890869, "logged_at": 1746304015.0014093}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8754057884216309, "logged_at": 1746304038.169734}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0083131790161133, "logged_at": 1746304039.1786206}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 2.844655990600586, "logged_at": 1746304066.8487945}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7151427268981934, "logged_at": 1746304071.7016766}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.2118170261383057, "logged_at": 1746304106.1706285}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.013418197631836, "logged_at": 1746304145.6212945}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.9435544013977051, "logged_at": 1746304146.5656757}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.4460382461547852, "logged_at": 1746304180.813974}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.1614913940429688, "logged_at": 1746304208.1843536}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.1763391494750977, "logged_at": 1746304248.0457528}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.5473873615264893, "logged_at": 1746304278.7285552}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0406250953674316, "logged_at": 1746304307.2457962}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.6960058212280273, "logged_at": 1746304336.009764}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.4275000095367432, "logged_at": 1746304378.6371534}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.4595527648925781, "logged_at": 1746304436.255214}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.6872401237487793, "logged_at": 1746304465.0918512}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.4492862224578857, "logged_at": 1746304492.5782344}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.201025485992432, "logged_at": 1746304529.5398955}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 3.752751350402832, "logged_at": 1746304575.0927444}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7375912666320801, "logged_at": 1746304612.1509793}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7495894432067871, "logged_at": 1746304612.9015024}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.0318078994750977, "logged_at": 1746304644.8349187}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.9622576236724854, "logged_at": 1746304645.7989662}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7955279350280762, "logged_at": 1746304646.596391}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7891638278961182, "logged_at": 1746304676.836302}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.9275968074798584, "logged_at": 1746304711.7581673}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7297422885894775, "logged_at": 1746304727.7338474}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.5557770729064941, "logged_at": 1746304746.2017171}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6165347099304199, "logged_at": 1746304746.819706}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.9175121784210205, "logged_at": 1746304770.9070702}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.054969310760498, "logged_at": 1746304801.3095162}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.266380786895752, "logged_at": 1746304830.3696694}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8228514194488525, "logged_at": 1746306782.3958726}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.0724520683288574, "logged_at": 1746306807.574652}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.9934754371643066, "logged_at": 1746306808.5688899}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.1578395366668701, "logged_at": 1746306843.2565808}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5738468170166016, "logged_at": 1746306867.4513185}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.438256025314331, "logged_at": 1746306893.128095}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.9067392349243164, "logged_at": 1746306924.224781}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 3.821561336517334, "logged_at": 1746306997.7151968}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 3.583019971847534, "logged_at": 1746307024.8353906}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 2.106109857559204, "logged_at": 1746307053.3215044}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 4.125965118408203, "logged_at": 1746307089.2759156}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.9035825729370117, "logged_at": 1746307136.1558912}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.757490873336792, "logged_at": 1746307166.204943}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.7078049182891846, "logged_at": 1746307200.215595}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 30.027894973754883, "logged_at": 1746307259.9403608}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 7.2903149127960205, "logged_at": 1746307299.2636662}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.9700253009796143, "logged_at": 1746307339.9647067}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6979727745056152, "logged_at": 1746307372.9718018}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7755274772644043, "logged_at": 1746307373.749297}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.739647388458252, "logged_at": 1746307407.289703}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.2109546661376953, "logged_at": 1746307408.5050664}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7739531993865967, "logged_at": 1746307409.2811537}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.5665714740753174, "logged_at": 1746307410.8495388}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.6736974716186523, "logged_at": 1746307411.5263212}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.6673805713653564, "logged_at": 1746307421.250943}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7186129093170166, "logged_at": 1746307439.5052218}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7045581340789795, "logged_at": 1746307440.211416}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.9544975757598877, "logged_at": 1746307441.1677399}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.0432815551757812, "logged_at": 1746307442.2125373}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.9958078861236572, "logged_at": 1746307466.5407727}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 4.733926057815552, "logged_at": 1746307494.9705617}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.1409106254577637, "logged_at": 1746307508.473702}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.932051420211792, "logged_at": 1746307531.9634852}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.8769516944885254, "logged_at": 1746307561.812274}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.9843225479125977, "logged_at": 1746307593.0099185}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.2294483184814453, "logged_at": 1746307594.2423573}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.955054759979248, "logged_at": 1746307596.1998649}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 2.0698955059051514, "logged_at": 1746307624.8890488}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.8708312511444092, "logged_at": 1746307626.7653682}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.4591953754425049, "logged_at": 1746307649.2081525}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 4.07980751991272, "logged_at": 1746307689.6379533}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 4.53719425201416, "logged_at": 1746307738.2064822}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 4.015673875808716, "logged_at": 1746307765.342486}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.939297914505005, "logged_at": 1746307815.40706}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 25.575225114822388, "logged_at": 1746307870.9043937}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 11.973790645599365, "logged_at": 1746307906.594298}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.8976531028747559, "logged_at": 1746388401.7995894}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.919452428817749, "logged_at": 1746388402.7195442}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.9194850921630859, "logged_at": 1746388420.4784982}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 1.051001787185669, "logged_at": 1746388421.529929}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0152771472930908, "logged_at": 1746388516.9643292}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0536670684814453, "logged_at": 1746388518.0183632}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.2130076885223389, "logged_at": 1746388641.6018362}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.2228858470916748, "logged_at": 1746388642.8252203}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 2.524566888809204, "logged_at": 1746388838.9445183}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 2.5987443923950195, "logged_at": 1746388841.5435638}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.7768440246582031, "logged_at": 1746388935.586241}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.76613450050354, "logged_at": 1746389004.6016245}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0074641704559326, "logged_at": 1746389116.6174295}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.8622915744781494, "logged_at": 1746389242.5140042}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 1.9787631034851074, "logged_at": 1746389454.1399877}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.8110549449920654, "logged_at": 1746389522.1799905}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.8035507202148438, "logged_at": 1746389555.0020034}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.322723388671875, "logged_at": 1746389611.2720895}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.9391272068023682, "logged_at": 1746389739.9016273}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 1.5331025123596191, "logged_at": 1746391698.739104}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.6853454113006592, "logged_at": 1746391770.2176156}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.6796040534973145, "logged_at": 1746391837.6569433}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0382699966430664, "logged_at": 1746391926.5545034}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.3310537338256836, "logged_at": 1746392068.395551}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 4.908606767654419, "logged_at": 1746392250.7364058}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.6027548313140869, "logged_at": 1746392316.829649}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.6221709251403809, "logged_at": 1746392337.053677}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.6009976863861084, "logged_at": 1746392434.5029652}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.3304955959320068, "logged_at": 1746392509.8326504}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 6.183981895446777, "logged_at": 1746392662.7477977}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 3.083491563796997, "logged_at": 1746393759.8637512}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 12.990243911743164, "logged_at": 1746393791.2668357}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 5.691296577453613, "logged_at": 1746393807.3977067}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 3.139296293258667, "logged_at": 1746393826.1252775}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 3.0477042198181152, "logged_at": 1746393842.7047222}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 3.166830062866211, "logged_at": 1746393845.8720148}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 2.9883809089660645, "logged_at": 1746393848.861083}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 2.2908637523651123, "logged_at": 1746393851.1523812}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 2.447486162185669, "logged_at": 1746393853.6002717}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 8.036900043487549, "logged_at": 1746393863.0190852}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 3.1469037532806396, "logged_at": 1746393866.1666873}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 2.8115339279174805, "logged_at": 1746393882.6300714}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 3.054779529571533, "logged_at": 1746393893.1749926}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 6.774125337600708, "logged_at": 1746393915.2606452}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 4.007734060287476, "logged_at": 1746393919.2689788}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 7.5357985496521, "logged_at": 1746393939.9440703}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 3.6880171298980713, "logged_at": 1746393973.3723593}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 4.708905458450317, "logged_at": 1746393993.8540337}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 3.2677981853485107, "logged_at": 1746394003.2069046}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 7.179643154144287, "logged_at": 1746394052.3473148}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 3.668759346008301, "logged_at": 1746394062.6955037}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 3.2462620735168457, "logged_at": 1746394085.0067623}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 5.180853843688965, "logged_at": 1746394113.7074232}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 4.9190428256988525, "logged_at": 1746394134.2312248}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 5.202957391738892, "logged_at": 1746394162.3625603}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 9.718572616577148, "logged_at": 1746394199.2862234}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 5.729352712631226, "logged_at": 1746394225.3567147}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 4.161798477172852, "logged_at": 1746394253.7115934}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 9.790580034255981, "logged_at": 1746394279.8589551}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 6.214760780334473, "logged_at": 1746394318.3361752}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 7.630018949508667, "logged_at": 1746394346.1087265}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 4.917167901992798, "logged_at": 1746394377.9817944}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 10.12967324256897, "logged_at": 1746394408.488262}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 14.837889671325684, "logged_at": 1746395534.7013497}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 6.993095874786377, "logged_at": 1746395590.4773316}
