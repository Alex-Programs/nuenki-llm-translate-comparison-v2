{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.2971374988555908, "logged_at": 1746211472.9286861}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0765833854675293, "logged_at": 1746211783.370438}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.3685879707336426, "logged_at": 1746211787.1185544}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.069000244140625, "logged_at": 1746211790.7366006}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.8569920063018799, "logged_at": 1746211794.2054276}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.0772123336791992, "logged_at": 1746211797.0984743}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.9451971054077148, "logged_at": 1746211800.2987897}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.0933082103729248, "logged_at": 1746211803.3948822}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.792569875717163, "logged_at": 1746211807.5711036}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.4829010963439941, "logged_at": 1746212487.0174334}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0717182159423828, "logged_at": 1746212520.2708032}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.3436522483825684, "logged_at": 1746212523.9945402}
{"model_id": null, "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.1823527812957764, "logged_at": 1746212528.507721}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.8673708438873291, "logged_at": 1746212532.539399}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.4229133129119873, "logged_at": 1746214641.5754607}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.805009365081787, "logged_at": 1746214645.8837957}
{"model_id": null, "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.7997024059295654, "logged_at": 1746214649.6672833}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.2835111618041992, "logged_at": 1746214736.2822955}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.1066174507141113, "logged_at": 1746214739.1520545}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.060647964477539, "logged_at": 1746214741.1559622}
{"model_id": null, "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.063253402709961, "logged_at": 1746214743.1563036}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 2.11576771736145, "logged_at": 1746214747.2124276}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.3861842155456543, "logged_at": 1746214753.8020198}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.657794713973999, "logged_at": 1746214756.362567}
{"model_id": null, "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.592878818511963, "logged_at": 1746214759.4215944}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.122992753982544, "logged_at": 1746214764.6260047}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.298855781555176, "logged_at": 1746214768.030071}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 3.1206953525543213, "logged_at": 1746214772.17649}
{"model_id": null, "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.0200612545013428, "logged_at": 1746214776.075655}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.3813912868499756, "logged_at": 1746216518.472969}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.043968915939331, "logged_at": 1746216519.5173886}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.8143436908721924, "logged_at": 1746216520.3324056}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.655975341796875, "logged_at": 1746216520.9888875}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.9782993793487549, "logged_at": 1746216521.967854}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.9143490791320801, "logged_at": 1746216522.8826344}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.4005987644195557, "logged_at": 1746216524.2837217}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 4.494946002960205, "logged_at": 1746216528.778989}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.0037288665771484, "logged_at": 1746216529.7831657}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.915215253829956, "logged_at": 1746216530.698729}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.9528858661651611, "logged_at": 1746216531.6520152}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.1788363456726074, "logged_at": 1746216532.8312678}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8996589183807373, "logged_at": 1746216533.731411}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.9251580238342285, "logged_at": 1746216534.6568978}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.1973156929016113, "logged_at": 1746216535.8546662}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8175129890441895, "logged_at": 1746216536.6725998}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.2242021560668945, "logged_at": 1746216537.8975108}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.037571907043457, "logged_at": 1746216538.9354959}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.1098737716674805, "logged_at": 1746216540.045844}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.2858030796051025, "logged_at": 1746216541.3320165}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8562989234924316, "logged_at": 1746216542.1886919}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.070509910583496, "logged_at": 1746216543.2594712}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.9394426345825195, "logged_at": 1746216546.642025}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.0253551006317139, "logged_at": 1746216547.6677976}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.0558159351348877, "logged_at": 1746216548.7242365}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.431997537612915, "logged_at": 1746216550.1566799}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.2980356216430664, "logged_at": 1746216553.9945736}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9829599857330322, "logged_at": 1746216554.9779897}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.7029383182525635, "logged_at": 1746216558.6113653}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.5949923992156982, "logged_at": 1746216560.2067733}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.2915356159210205, "logged_at": 1746216568.3308485}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.1842389106750488, "logged_at": 1746216569.5153747}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 4.083331108093262, "logged_at": 1746216580.6677268}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.9503273963928223, "logged_at": 1746216584.618583}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.6506834030151367, "logged_at": 1746216599.5800488}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 3.087787389755249, "logged_at": 1746216602.66815}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.478583812713623, "logged_at": 1746216611.4164348}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.655756950378418, "logged_at": 1746216613.0725446}
{"model_id": "GPT 4.1OpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.1154472827911377, "logged_at": 1746216622.6395938}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.181455612182617, "logged_at": 1746216624.8213608}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8395907878875732, "logged_at": 1746216630.5218334}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7893872261047363, "logged_at": 1746216638.4830232}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.8291325569152832, "logged_at": 1746216644.7422893}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.7166414260864258, "logged_at": 1746216647.5856574}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.974576473236084, "logged_at": 1746216648.5607064}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7724394798278809, "logged_at": 1746216649.333541}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7487421035766602, "logged_at": 1746216650.0828693}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.5991764068603516, "logged_at": 1746216650.6823492}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8969020843505859, "logged_at": 1746216651.5795746}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.3460907936096191, "logged_at": 1746216652.9260325}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8586239814758301, "logged_at": 1746216656.5373297}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7872567176818848, "logged_at": 1746216657.3249426}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.3034148216247559, "logged_at": 1746216669.603194}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.1099107265472412, "logged_at": 1746216672.9619737}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.5199778079986572, "logged_at": 1746216676.8126874}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.586740493774414, "logged_at": 1746216685.6135652}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 5.736400365829468, "logged_at": 1746216701.874441}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.8205294609069824, "logged_at": 1746216718.0339384}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.3281970024108887, "logged_at": 1746216731.0148106}
{"model_id": "GPT 4oOpenAIOpenrouter0.5", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.1499011516571045, "logged_at": 1746216746.9333465}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.912585973739624, "logged_at": 1746277713.5564468}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0142803192138672, "logged_at": 1746277723.0998485}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.6935594081878662, "logged_at": 1746277723.79379}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.7323369979858398, "logged_at": 1746277727.5507646}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7751405239105225, "logged_at": 1746277728.3264375}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.8030543327331543, "logged_at": 1746277729.1298897}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.839421272277832, "logged_at": 1746277729.9699075}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8233723640441895, "logged_at": 1746277730.7936037}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8534591197967529, "logged_at": 1746277731.6473641}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.05008864402771, "logged_at": 1746277742.3893907}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.9002816677093506, "logged_at": 1746277745.5591109}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.0070714950561523, "logged_at": 1746277746.5681455}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5343971252441406, "logged_at": 1746277754.4675303}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9011867046356201, "logged_at": 1746277758.5176008}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.2018327713012695, "logged_at": 1746277759.72112}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.3477964401245117, "logged_at": 1746277769.5929942}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.5867974758148193, "logged_at": 1746277780.454946}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.148885488510132, "logged_at": 1746277795.5391886}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 4.162233352661133, "logged_at": 1746277813.4324467}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.3942108154296875, "logged_at": 1746277823.0032916}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8508336544036865, "logged_at": 1746277833.5331154}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.5877823829650879, "logged_at": 1746277845.4788647}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7314450740814209, "logged_at": 1746277846.2114992}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.6590907573699951, "logged_at": 1746277849.277307}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6843874454498291, "logged_at": 1746277849.962255}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7290632724761963, "logged_at": 1746277850.6919188}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8601009845733643, "logged_at": 1746277851.5525465}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.602961540222168, "logged_at": 1746277858.992146}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8453369140625, "logged_at": 1746277859.8380811}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0336852073669434, "logged_at": 1746277860.8724906}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.7648942470550537, "logged_at": 1746277864.4469016}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.87939453125, "logged_at": 1746277865.3267195}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.8104362487792969, "logged_at": 1746277866.1384475}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.3756024837493896, "logged_at": 1746277869.5187416}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 0.8708932399749756, "logged_at": 1746277872.9482586}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.486497163772583, "logged_at": 1746277882.3401015}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 1.7144837379455566, "logged_at": 1746277901.9204688}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.3752329349517822, "logged_at": 1746277924.7518687}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.7635483741760254, "logged_at": 1746278452.5601234}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.7139694690704346, "logged_at": 1746278468.2195387}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.7973818778991699, "logged_at": 1746278477.3632388}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.8961849212646484, "logged_at": 1746278486.2346747}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.6577682495117188, "logged_at": 1746278486.893045}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.6710238456726074, "logged_at": 1746278490.6376822}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6046218872070312, "logged_at": 1746278491.2429078}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.6823492050170898, "logged_at": 1746278491.9257832}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7833187580108643, "logged_at": 1746278492.7096376}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.6023008823394775, "logged_at": 1746278493.3124573}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.3715956211090088, "logged_at": 1746278494.684624}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.7780966758728027, "logged_at": 1746278495.463282}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8651754856109619, "logged_at": 1746278498.982859}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.8070175647735596, "logged_at": 1746278499.7909703}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.0584626197814941, "logged_at": 1746278500.8500419}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9616904258728027, "logged_at": 1746278503.8701355}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 0.8783295154571533, "logged_at": 1746278505.7131383}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 0.959355354309082, "logged_at": 1746278516.0283897}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 1.9283511638641357, "logged_at": 1746278529.9825718}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.4718475341796875, "logged_at": 1746278541.5387573}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.2771389484405518, "logged_at": 1746278551.5328727}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.3733062744140625, "logged_at": 1746278562.22813}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.724318265914917, "logged_at": 1746278570.4358766}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 5.311007022857666, "logged_at": 1746278583.1205666}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.5785007476806641, "logged_at": 1746278583.7003646}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.0545153617858887, "logged_at": 1746278587.0253942}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7202768325805664, "logged_at": 1746278587.7461102}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.8940427303314209, "logged_at": 1746278588.6408472}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7398619651794434, "logged_at": 1746278596.4726262}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 2.530003070831299, "logged_at": 1746278606.4154243}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 2.417092800140381, "logged_at": 1746278608.8329391}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.4833898544311523, "logged_at": 1746278739.0213053}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.169285535812378, "logged_at": 1746278997.2284126}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 2.9056193828582764, "logged_at": 1746279000.134578}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.2424538135528564, "logged_at": 1746279001.3787124}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 16.179057121276855, "logged_at": 1746279021.0047805}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 5.212327241897583, "logged_at": 1746279028.4981906}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 2.776808023452759, "logged_at": 1746279039.3967817}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.8193531036376953, "logged_at": 1746279051.5667002}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 4.1032798290252686, "logged_at": 1746279078.848498}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 13.046830177307129, "logged_at": 1746279100.386233}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 5.354496717453003, "logged_at": 1746279113.8624418}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.4293689727783203, "logged_at": 1746279124.4153554}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.591954231262207, "logged_at": 1746279133.6408396}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 2.1518051624298096, "logged_at": 1746279135.8098454}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.0205388069152832, "logged_at": 1746279136.8310776}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7644402980804443, "logged_at": 1746279137.5960667}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.654280424118042, "logged_at": 1746279138.2506316}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 4.075302600860596, "logged_at": 1746279142.3270147}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 3.1775736808776855, "logged_at": 1746279145.5051758}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.4036660194396973, "logged_at": 1746279146.909524}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.2060351371765137, "logged_at": 1746279148.1161685}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.6892538070678711, "logged_at": 1746279152.9577658}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.2684106826782227, "logged_at": 1746279154.2267432}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.3304030895233154, "logged_at": 1746279163.1930838}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.9317634105682373, "logged_at": 1746279165.125596}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.0787336826324463, "logged_at": 1746279170.4831605}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 4.173696756362915, "logged_at": 1746279182.9465678}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 7.157452583312988, "logged_at": 1746279190.104731}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 6.467875003814697, "logged_at": 1746279206.3111153}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 3.6932578086853027, "logged_at": 1746279222.6736138}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 15.040959358215332, "logged_at": 1746279245.6897879}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 2.070071220397949, "logged_at": 1746283724.2336206}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.175955057144165, "logged_at": 1746283725.4099143}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.8909296989440918, "logged_at": 1746283726.3015213}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.0316641330718994, "logged_at": 1746283727.3336143}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.0542187690734863, "logged_at": 1746283728.3888805}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7480161190032959, "logged_at": 1746283729.1372}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.8571054935455322, "logged_at": 1746283732.6767051}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.795621395111084, "logged_at": 1746283733.472806}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.061798095703125, "logged_at": 1746283746.0226617}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.00972580909729, "logged_at": 1746283747.032764}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.8695633411407471, "logged_at": 1746283755.9421797}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0412404537200928, "logged_at": 1746283756.9836683}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.9193878173828125, "logged_at": 1746283758.90753}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.4444494247436523, "logged_at": 1746283760.3522675}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.2155468463897705, "logged_at": 1746283781.0847216}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0978171825408936, "logged_at": 1746283782.1830127}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.6580426692962646, "logged_at": 1746283790.7978466}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.7464275360107422, "logged_at": 1746283792.5445833}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 3.067359447479248, "logged_at": 1746283803.5165892}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.641279697418213, "logged_at": 1746283806.158396}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.1160080432891846, "logged_at": 1746283809.989143}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6352405548095703, "logged_at": 1746283810.6248844}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6694724559783936, "logged_at": 1746283818.7206528}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.6605515480041504, "logged_at": 1746283821.3464727}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1561996936798096, "logged_at": 1746283840.5091813}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0633544921875, "logged_at": 1746283848.7037826}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 0.9935872554779053, "logged_at": 1746283856.592645}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0642266273498535, "logged_at": 1746283877.0501266}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 4.446897745132446, "logged_at": 1746283889.5357313}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.245124101638794, "logged_at": 1746283899.841608}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.8255293369293213, "logged_at": 1746283908.5371046}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6745331287384033, "logged_at": 1746283909.2121637}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6902265548706055, "logged_at": 1746283909.9035938}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.8587236404418945, "logged_at": 1746283966.4683251}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.940014123916626, "logged_at": 1746283967.4114387}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0770068168640137, "logged_at": 1746283968.4889467}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.2864127159118652, "logged_at": 1746283969.7811353}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0443429946899414, "logged_at": 1746283992.241054}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.351135015487671, "logged_at": 1746284003.6049225}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.5818099975585938, "logged_at": 1746284013.8875709}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.3214025497436523, "logged_at": 1746284018.547091}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6012134552001953, "logged_at": 1746284020.017902}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7786316871643066, "logged_at": 1746284027.8114266}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.8379766941070557, "logged_at": 1746284029.6506267}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.3566136360168457, "logged_at": 1746284044.7556105}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.1680619716644287, "logged_at": 1746284053.671373}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 2.356259822845459, "logged_at": 1746284064.296307}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.8145720958709717, "logged_at": 1746284086.3877108}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 4.589008331298828, "logged_at": 1746284096.945929}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 16.36616086959839, "logged_at": 1746284121.3958037}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.46372652053833, "logged_at": 1746284127.9161167}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.8752973079681396, "logged_at": 1746284129.7114005}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6654727458953857, "logged_at": 1746284130.3790064}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 5.524034738540649, "logged_at": 1746284135.9035065}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.4114775657653809, "logged_at": 1746284155.2923415}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.9689235687255859, "logged_at": 1746284169.0619414}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 3.7981510162353516, "logged_at": 1746284179.9463186}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.7604129314422607, "logged_at": 1746284198.3348129}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 19.511823892593384, "logged_at": 1746284227.7621005}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 5.157696962356567, "logged_at": 1746284237.4419923}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 2.312882900238037, "logged_at": 1746297975.62049}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.3125414848327637, "logged_at": 1746297976.9333942}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.495391607284546, "logged_at": 1746298022.4502997}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.0120179653167725, "logged_at": 1746298023.4627047}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.9893252849578857, "logged_at": 1746298024.4524994}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.9021763801574707, "logged_at": 1746298026.3551033}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.1807785034179688, "logged_at": 1746298054.4479587}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.9674625396728516, "logged_at": 1746298055.4158885}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.9967596530914307, "logged_at": 1746298057.4131866}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.3225440979003906, "logged_at": 1746298058.7362208}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.034609079360962, "logged_at": 1746298083.7639177}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.1503400802612305, "logged_at": 1746298084.9146457}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.0216078758239746, "logged_at": 1746298085.9369357}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.2222049236297607, "logged_at": 1746298087.159412}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.0013995170593262, "logged_at": 1746298088.161143}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.1140761375427246, "logged_at": 1746298089.2755451}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.997079610824585, "logged_at": 1746298090.2731328}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.177112340927124, "logged_at": 1746298091.4505544}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.0373897552490234, "logged_at": 1746298092.4884393}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.9966559410095215, "logged_at": 1746298093.4854004}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7779500484466553, "logged_at": 1746298094.263672}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7090482711791992, "logged_at": 1746298094.972956}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.3155553340911865, "logged_at": 1746298096.2889144}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.1829028129577637, "logged_at": 1746298097.4721782}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.22324800491333, "logged_at": 1746298129.1591585}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.3680500984191895, "logged_at": 1746298130.527745}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.1827867031097412, "logged_at": 1746298131.7111423}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.7459721565246582, "logged_at": 1746298133.4575589}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.993480920791626, "logged_at": 1746298163.1001453}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.9981772899627686, "logged_at": 1746298164.0989084}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.3902297019958496, "logged_at": 1746298165.4898522}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.1941030025482178, "logged_at": 1746298166.6845596}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 2.152752161026001, "logged_at": 1746298189.650929}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 3.718883752822876, "logged_at": 1746298193.3700778}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.8249561786651611, "logged_at": 1746298217.7707064}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.3200123310089111, "logged_at": 1746298219.0911214}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.4460086822509766, "logged_at": 1746298244.6782568}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.3853085041046143, "logged_at": 1746298246.0640323}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.5763866901397705, "logged_at": 1746298278.7417078}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.8818697929382324, "logged_at": 1746298280.6240394}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.6937017440795898, "logged_at": 1746298316.1307216}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.524998426437378, "logged_at": 1746298317.6560044}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.6675982475280762, "logged_at": 1746298347.6923943}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.6766724586486816, "logged_at": 1746298349.3695102}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.157897710800171, "logged_at": 1746298388.438237}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.5323400497436523, "logged_at": 1746298389.9710667}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.4646437168121338, "logged_at": 1746298437.2990732}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 2.8417325019836426, "logged_at": 1746298440.141598}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.5296313762664795, "logged_at": 1746298442.671837}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.9329729080200195, "logged_at": 1746298445.6050775}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 3.6563241481781006, "logged_at": 1746298491.1027546}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.163916826248169, "logged_at": 1746298493.2672558}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.781658172607422, "logged_at": 1746298533.9326882}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.188013792037964, "logged_at": 1746298536.1210825}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.9930009841918945, "logged_at": 1746298595.1210248}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.428231716156006, "logged_at": 1746298597.549741}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.426804304122925, "logged_at": 1746298625.8734324}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.171823501586914, "logged_at": 1746298628.045696}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 3.27384352684021, "logged_at": 1746298664.1139011}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.766407012939453, "logged_at": 1746298666.8807933}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.0463001728057861, "logged_at": 1746298737.744995}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6324577331542969, "logged_at": 1746298794.3541903}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7163650989532471, "logged_at": 1746298795.0712416}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.7504503726959229, "logged_at": 1746298818.4656682}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.7789974212646484, "logged_at": 1746298819.2452326}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6338682174682617, "logged_at": 1746298842.7760253}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7755212783813477, "logged_at": 1746298864.771493}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.381812334060669, "logged_at": 1746298866.1537755}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8562617301940918, "logged_at": 1746298867.0107887}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 5.312146186828613, "logged_at": 1746298893.4197402}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.8100476264953613, "logged_at": 1746298894.2304747}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.6715872287750244, "logged_at": 1746298894.9027948}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8296713829040527, "logged_at": 1746298924.580539}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.9327678680419922, "logged_at": 1746298925.5141392}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8408341407775879, "logged_at": 1746298954.5507233}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7636599540710449, "logged_at": 1746298978.9307406}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1772749423980713, "logged_at": 1746298980.1084352}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.9827625751495361, "logged_at": 1746299017.8091595}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5044667720794678, "logged_at": 1746299051.6385918}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 4.960722923278809, "logged_at": 1746299081.7680726}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.2163021564483643, "logged_at": 1746299108.4068193}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.017157793045044, "logged_at": 1746299138.9721382}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.3252437114715576, "logged_at": 1746299177.8132274}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.1108951568603516, "logged_at": 1746299212.0768821}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.151233673095703, "logged_at": 1746299270.8446577}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.8177294731140137, "logged_at": 1746299347.420337}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.7412934303283691, "logged_at": 1746299401.3186302}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.9627857208251953, "logged_at": 1746299441.4718769}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.4573721885681152, "logged_at": 1746299510.8516781}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.0989694595336914, "logged_at": 1746299554.9336545}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.0347075462341309, "logged_at": 1746299642.6262984}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.9735739231109619, "logged_at": 1746299682.287019}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.8516180515289307, "logged_at": 1746299703.171596}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.6331417560577393, "logged_at": 1746299725.2616265}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.0804784297943115, "logged_at": 1746299726.3427546}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7784457206726074, "logged_at": 1746299727.1219485}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7742681503295898, "logged_at": 1746299738.9358654}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7070186138153076, "logged_at": 1746299766.2802505}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7019038200378418, "logged_at": 1746299766.9827204}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7798902988433838, "logged_at": 1746299767.7629445}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.9921929836273193, "logged_at": 1746299768.7555497}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.87538743019104, "logged_at": 1746299769.6315293}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.063281536102295, "logged_at": 1746299795.1056898}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.9179954528808594, "logged_at": 1746299796.0241446}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8855819702148438, "logged_at": 1746299821.886059}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7869315147399902, "logged_at": 1746299845.9853983}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.9858150482177734, "logged_at": 1746299878.0259655}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0029263496398926, "logged_at": 1746299911.187298}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5801851749420166, "logged_at": 1746299912.7684588}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.9132480621337891, "logged_at": 1746299945.254491}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.289494514465332, "logged_at": 1746299979.3987489}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 0.9401853084564209, "logged_at": 1746300006.0283265}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.196204423904419, "logged_at": 1746300033.889116}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.281299114227295, "logged_at": 1746300062.5434933}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.943415403366089, "logged_at": 1746300090.7635214}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.7201757431030273, "logged_at": 1746300139.1050448}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.9413857460021973, "logged_at": 1746300184.8953009}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.7562177181243896, "logged_at": 1746300219.9350066}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 3.088459014892578, "logged_at": 1746300267.6777806}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.202486276626587, "logged_at": 1746300307.4295096}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.965749979019165, "logged_at": 1746300368.999551}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6446301937103271, "logged_at": 1746300433.662373}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 4.094383478164673, "logged_at": 1746300443.23413}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.640758752822876, "logged_at": 1746300469.738534}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 2.5795648097991943, "logged_at": 1746300472.3187418}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7413904666900635, "logged_at": 1746300473.0605786}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6408901214599609, "logged_at": 1746300473.7021823}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7540552616119385, "logged_at": 1746300500.476672}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7635085582733154, "logged_at": 1746300501.2405758}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8713483810424805, "logged_at": 1746300526.0176091}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.666358232498169, "logged_at": 1746300555.0390346}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.7529599666595459, "logged_at": 1746300573.4340994}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.3174774646759033, "logged_at": 1746300601.0714946}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 2.4013619422912598, "logged_at": 1746300631.5543494}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 3.389629364013672, "logged_at": 1746300654.682045}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.9924685955047607, "logged_at": 1746300677.3616505}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.5340125560760498, "logged_at": 1746300701.8771722}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.3202002048492432, "logged_at": 1746300733.2444608}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.2181107997894287, "logged_at": 1746300764.56198}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 4.747503995895386, "logged_at": 1746300793.6680875}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.066340446472168, "logged_at": 1746300838.2975945}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 2.3562417030334473, "logged_at": 1746300873.8925726}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.9269824028015137, "logged_at": 1746300903.886142}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.6288118362426758, "logged_at": 1746300942.9324245}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 5.287922143936157, "logged_at": 1746300986.8512614}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 4.286499738693237, "logged_at": 1746301037.1809945}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 4.757099628448486, "logged_at": 1746301118.5717123}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 5.635262727737427, "logged_at": 1746301161.504968}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 7.219548940658569, "logged_at": 1746301205.7008858}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.7057256698608398, "logged_at": 1746302279.3985467}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.0031311511993408, "logged_at": 1746302280.4022498}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.9837353229522705, "logged_at": 1746302312.9171815}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.1484298706054688, "logged_at": 1746302314.0660174}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.013606071472168, "logged_at": 1746302315.0802667}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.8623197078704834, "logged_at": 1746302315.9430487}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.8054468631744385, "logged_at": 1746302350.839676}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.9381897449493408, "logged_at": 1746302351.778133}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.0952794551849365, "logged_at": 1746302352.8738444}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.5708470344543457, "logged_at": 1746302354.4450023}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.936887264251709, "logged_at": 1746302355.3822536}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.9919288158416748, "logged_at": 1746302356.3745604}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7213425636291504, "logged_at": 1746302357.0963938}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7431797981262207, "logged_at": 1746302357.8398213}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.0259513854980469, "logged_at": 1746302358.866175}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.1418890953063965, "logged_at": 1746302360.0084677}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.9860987663269043, "logged_at": 1746302360.9948914}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8931279182434082, "logged_at": 1746302361.888278}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8353359699249268, "logged_at": 1746302362.7239256}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.0791809558868408, "logged_at": 1746302363.8033702}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.0443525314331055, "logged_at": 1746302391.3356876}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.9524681568145752, "logged_at": 1746302392.2884731}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.7797515392303467, "logged_at": 1746302393.068885}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.8837881088256836, "logged_at": 1746302393.9530666}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.1829609870910645, "logged_at": 1746302395.1365955}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.9733998775482178, "logged_at": 1746302396.1103876}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.061908483505249, "logged_at": 1746302413.7604659}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0605485439300537, "logged_at": 1746302414.8212502}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.1393096446990967, "logged_at": 1746302439.1178463}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.9015052318572998, "logged_at": 1746302440.0196183}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.991241455078125, "logged_at": 1746302441.0112314}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.011681079864502, "logged_at": 1746302442.0233138}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1773467063903809, "logged_at": 1746302465.3225918}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.1607823371887207, "logged_at": 1746302466.4836602}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.483780860900879, "logged_at": 1746302508.1312995}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.1241185665130615, "logged_at": 1746302509.2557752}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 2.0969464778900146, "logged_at": 1746302534.9201767}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.2825608253479004, "logged_at": 1746302536.2033055}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.164257287979126, "logged_at": 1746302556.7040334}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.2979555130004883, "logged_at": 1746302558.0031092}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.357257604598999, "logged_at": 1746302595.5736167}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.2306931018829346, "logged_at": 1746302596.80474}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.6637864112854004, "logged_at": 1746302626.4976106}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.480231523513794, "logged_at": 1746302627.9781637}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.6131856441497803, "logged_at": 1746302655.6857471}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.056624174118042, "logged_at": 1746302656.7426908}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.6303069591522217, "logged_at": 1746302702.2705548}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.3694565296173096, "logged_at": 1746302703.642465}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.6212375164031982, "logged_at": 1746302729.2506847}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.5706145763397217, "logged_at": 1746302731.8220162}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.8283777236938477, "logged_at": 1746302778.885419}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.7250328063964844, "logged_at": 1746302780.6108096}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.8589363098144531, "logged_at": 1746302807.6523721}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.144440174102783, "logged_at": 1746302809.7972906}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.6973512172698975, "logged_at": 1746302848.155671}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.8463685512542725, "logged_at": 1746302850.002983}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.082651376724243, "logged_at": 1746302886.7368872}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.4489119052886963, "logged_at": 1746302889.1867194}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.045053958892822, "logged_at": 1746302928.5211778}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.545274019241333, "logged_at": 1746302931.0667458}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8141770362854004, "logged_at": 1746303005.0275621}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6675088405609131, "logged_at": 1746303046.7106571}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7663455009460449, "logged_at": 1746303068.5932124}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.2518270015716553, "logged_at": 1746303091.0781596}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.8724780082702637, "logged_at": 1746303091.9512317}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.8008584976196289, "logged_at": 1746303115.2563255}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6105916500091553, "logged_at": 1746303144.5974867}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7252011299133301, "logged_at": 1746303161.5224926}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.8217813968658447, "logged_at": 1746303162.3464975}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7679107189178467, "logged_at": 1746303186.3341353}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7523050308227539, "logged_at": 1746303204.2339425}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.769129753112793, "logged_at": 1746303205.0034795}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.1186532974243164, "logged_at": 1746303238.9082594}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0079069137573242, "logged_at": 1746303239.9183686}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.7452547550201416, "logged_at": 1746303267.559062}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.8524706363677979, "logged_at": 1746303293.430816}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.9663803577423096, "logged_at": 1746303316.2332017}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.092477560043335, "logged_at": 1746303359.5014808}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.9779894351959229, "logged_at": 1746303385.7687442}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.354477882385254, "logged_at": 1746303413.5335333}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.0864009857177734, "logged_at": 1746303441.164755}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.0398147106170654, "logged_at": 1746303468.526466}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.4572436809539795, "logged_at": 1746303528.5782783}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.02470064163208, "logged_at": 1746303560.120735}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.6758553981781006, "logged_at": 1746303598.9846096}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.7366564273834229, "logged_at": 1746303646.6693075}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.7952184677124023, "logged_at": 1746303684.5665286}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 3.551130771636963, "logged_at": 1746303716.7141757}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.2689208984375, "logged_at": 1746303766.6910756}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.3181400299072266, "logged_at": 1746303807.2792826}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8126816749572754, "logged_at": 1746303889.119393}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7470035552978516, "logged_at": 1746303925.3149104}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7803421020507812, "logged_at": 1746303926.096143}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.8372888565063477, "logged_at": 1746303956.648037}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.0603656768798828, "logged_at": 1746303957.7091835}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.6632213592529297, "logged_at": 1746303958.3734877}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.6541845798492432, "logged_at": 1746303986.357271}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.8046810626983643, "logged_at": 1746304011.7717218}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.899486780166626, "logged_at": 1746304012.6734686}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7301619052886963, "logged_at": 1746304013.404645}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.8677859306335449, "logged_at": 1746304014.2734377}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.7275106906890869, "logged_at": 1746304015.0014093}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8754057884216309, "logged_at": 1746304038.169734}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0083131790161133, "logged_at": 1746304039.1786206}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 2.844655990600586, "logged_at": 1746304066.8487945}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7151427268981934, "logged_at": 1746304071.7016766}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.2118170261383057, "logged_at": 1746304106.1706285}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.013418197631836, "logged_at": 1746304145.6212945}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.9435544013977051, "logged_at": 1746304146.5656757}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.4460382461547852, "logged_at": 1746304180.813974}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.1614913940429688, "logged_at": 1746304208.1843536}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.1763391494750977, "logged_at": 1746304248.0457528}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.5473873615264893, "logged_at": 1746304278.7285552}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.0406250953674316, "logged_at": 1746304307.2457962}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.6960058212280273, "logged_at": 1746304336.009764}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.4275000095367432, "logged_at": 1746304378.6371534}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.4595527648925781, "logged_at": 1746304436.255214}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.6872401237487793, "logged_at": 1746304465.0918512}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.4492862224578857, "logged_at": 1746304492.5782344}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.201025485992432, "logged_at": 1746304529.5398955}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 3.752751350402832, "logged_at": 1746304575.0927444}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7375912666320801, "logged_at": 1746304612.1509793}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7495894432067871, "logged_at": 1746304612.9015024}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.0318078994750977, "logged_at": 1746304644.8349187}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.9622576236724854, "logged_at": 1746304645.7989662}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7955279350280762, "logged_at": 1746304646.596391}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.7891638278961182, "logged_at": 1746304676.836302}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.9275968074798584, "logged_at": 1746304711.7581673}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7297422885894775, "logged_at": 1746304727.7338474}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.5557770729064941, "logged_at": 1746304746.2017171}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6165347099304199, "logged_at": 1746304746.819706}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.9175121784210205, "logged_at": 1746304770.9070702}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.054969310760498, "logged_at": 1746304801.3095162}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.266380786895752, "logged_at": 1746304830.3696694}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8228514194488525, "logged_at": 1746306782.3958726}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.0724520683288574, "logged_at": 1746306807.574652}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.9934754371643066, "logged_at": 1746306808.5688899}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.1578395366668701, "logged_at": 1746306843.2565808}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.5738468170166016, "logged_at": 1746306867.4513185}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.438256025314331, "logged_at": 1746306893.128095}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.9067392349243164, "logged_at": 1746306924.224781}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 3.821561336517334, "logged_at": 1746306997.7151968}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 3.583019971847534, "logged_at": 1746307024.8353906}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 2.106109857559204, "logged_at": 1746307053.3215044}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 4.125965118408203, "logged_at": 1746307089.2759156}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.9035825729370117, "logged_at": 1746307136.1558912}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.757490873336792, "logged_at": 1746307166.204943}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.7078049182891846, "logged_at": 1746307200.215595}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 30.027894973754883, "logged_at": 1746307259.9403608}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 7.2903149127960205, "logged_at": 1746307299.2636662}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.9700253009796143, "logged_at": 1746307339.9647067}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.6979727745056152, "logged_at": 1746307372.9718018}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7755274772644043, "logged_at": 1746307373.749297}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.739647388458252, "logged_at": 1746307407.289703}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.2109546661376953, "logged_at": 1746307408.5050664}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7739531993865967, "logged_at": 1746307409.2811537}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.5665714740753174, "logged_at": 1746307410.8495388}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.6736974716186523, "logged_at": 1746307411.5263212}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.6673805713653564, "logged_at": 1746307421.250943}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7186129093170166, "logged_at": 1746307439.5052218}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.7045581340789795, "logged_at": 1746307440.211416}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.9544975757598877, "logged_at": 1746307441.1677399}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.0432815551757812, "logged_at": 1746307442.2125373}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.9958078861236572, "logged_at": 1746307466.5407727}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 4.733926057815552, "logged_at": 1746307494.9705617}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.1409106254577637, "logged_at": 1746307508.473702}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.932051420211792, "logged_at": 1746307531.9634852}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.8769516944885254, "logged_at": 1746307561.812274}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.9843225479125977, "logged_at": 1746307593.0099185}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.2294483184814453, "logged_at": 1746307594.2423573}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.955054759979248, "logged_at": 1746307596.1998649}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 2.0698955059051514, "logged_at": 1746307624.8890488}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.8708312511444092, "logged_at": 1746307626.7653682}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.4591953754425049, "logged_at": 1746307649.2081525}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 4.07980751991272, "logged_at": 1746307689.6379533}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 4.53719425201416, "logged_at": 1746307738.2064822}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 4.015673875808716, "logged_at": 1746307765.342486}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.939297914505005, "logged_at": 1746307815.40706}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 25.575225114822388, "logged_at": 1746307870.9043937}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 11.973790645599365, "logged_at": 1746307906.594298}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.8976531028747559, "logged_at": 1746388401.7995894}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.919452428817749, "logged_at": 1746388402.7195442}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.9194850921630859, "logged_at": 1746388420.4784982}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 1.051001787185669, "logged_at": 1746388421.529929}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0152771472930908, "logged_at": 1746388516.9643292}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0536670684814453, "logged_at": 1746388518.0183632}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.2130076885223389, "logged_at": 1746388641.6018362}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.2228858470916748, "logged_at": 1746388642.8252203}
{"model_id": "GPT 4.1OpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 2.524566888809204, "logged_at": 1746388838.9445183}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 2.5987443923950195, "logged_at": 1746388841.5435638}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.7768440246582031, "logged_at": 1746388935.586241}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.76613450050354, "logged_at": 1746389004.6016245}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0074641704559326, "logged_at": 1746389116.6174295}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.8622915744781494, "logged_at": 1746389242.5140042}
{"model_id": "GPT 4oOpenAIOpenrouter1", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 1.9787631034851074, "logged_at": 1746389454.1399877}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.8110549449920654, "logged_at": 1746389522.1799905}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.8035507202148438, "logged_at": 1746389555.0020034}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.322723388671875, "logged_at": 1746389611.2720895}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.9391272068023682, "logged_at": 1746389739.9016273}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 1.5331025123596191, "logged_at": 1746391698.739104}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.6853454113006592, "logged_at": 1746391770.2176156}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.6796040534973145, "logged_at": 1746391837.6569433}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.0382699966430664, "logged_at": 1746391926.5545034}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.3310537338256836, "logged_at": 1746392068.395551}
{"model_id": "Grok 3 BetaX AIOpenrouter1", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 4.908606767654419, "logged_at": 1746392250.7364058}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.6027548313140869, "logged_at": 1746392316.829649}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.6221709251403809, "logged_at": 1746392337.053677}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.6009976863861084, "logged_at": 1746392434.5029652}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.3304955959320068, "logged_at": 1746392509.8326504}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 6.183981895446777, "logged_at": 1746392662.7477977}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 3.083491563796997, "logged_at": 1746393759.8637512}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 12.990243911743164, "logged_at": 1746393791.2668357}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 5.691296577453613, "logged_at": 1746393807.3977067}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 3.139296293258667, "logged_at": 1746393826.1252775}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 3.0477042198181152, "logged_at": 1746393842.7047222}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 3.166830062866211, "logged_at": 1746393845.8720148}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 2.9883809089660645, "logged_at": 1746393848.861083}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 2.2908637523651123, "logged_at": 1746393851.1523812}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 2.447486162185669, "logged_at": 1746393853.6002717}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 8.036900043487549, "logged_at": 1746393863.0190852}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 3.1469037532806396, "logged_at": 1746393866.1666873}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 2.8115339279174805, "logged_at": 1746393882.6300714}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 3.054779529571533, "logged_at": 1746393893.1749926}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 6.774125337600708, "logged_at": 1746393915.2606452}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 4.007734060287476, "logged_at": 1746393919.2689788}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 7.5357985496521, "logged_at": 1746393939.9440703}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 3.6880171298980713, "logged_at": 1746393973.3723593}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 4.708905458450317, "logged_at": 1746393993.8540337}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 3.2677981853485107, "logged_at": 1746394003.2069046}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 7.179643154144287, "logged_at": 1746394052.3473148}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 3.668759346008301, "logged_at": 1746394062.6955037}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 3.2462620735168457, "logged_at": 1746394085.0067623}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 5.180853843688965, "logged_at": 1746394113.7074232}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 4.9190428256988525, "logged_at": 1746394134.2312248}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 5.202957391738892, "logged_at": 1746394162.3625603}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 9.718572616577148, "logged_at": 1746394199.2862234}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 5.729352712631226, "logged_at": 1746394225.3567147}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 4.161798477172852, "logged_at": 1746394253.7115934}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 9.790580034255981, "logged_at": 1746394279.8589551}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 6.214760780334473, "logged_at": 1746394318.3361752}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 7.630018949508667, "logged_at": 1746394346.1087265}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 4.917167901992798, "logged_at": 1746394377.9817944}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 10.12967324256897, "logged_at": 1746394408.488262}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 14.837889671325684, "logged_at": 1746395534.7013497}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 6.993095874786377, "logged_at": 1746395590.4773316}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.0437991619110107, "logged_at": 1746615548.9807844}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.1168291568756104, "logged_at": 1746615549.0610464}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 1.1333906650543213, "logged_at": 1746615549.069064}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.2146782875061035, "logged_at": 1746615549.1553137}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.3103370666503906, "logged_at": 1746615549.2494273}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.3919720649719238, "logged_at": 1746615549.3231144}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.4519195556640625, "logged_at": 1746615549.3977141}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.4592547416687012, "logged_at": 1746615549.4022162}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.5372941493988037, "logged_at": 1746615549.4713194}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.786200761795044, "logged_at": 1746615549.736504}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.8790504932403564, "logged_at": 1746615549.828217}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.9188294410705566, "logged_at": 1746615549.8663943}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.978611707687378, "logged_at": 1746615549.9270623}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 2.1718533039093018, "logged_at": 1746615550.12144}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.8364315032958984, "logged_at": 1746615550.7916412}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 2.837050199508667, "logged_at": 1746615550.7919416}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 3.0827488899230957, "logged_at": 1746615551.0386746}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.8480546474456787, "logged_at": 1746615551.799875}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 5.381458044052124, "logged_at": 1746615553.3092048}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 5.566490173339844, "logged_at": 1746615553.5047042}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 5.581314563751221, "logged_at": 1746615553.522797}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 5.720952272415161, "logged_at": 1746615553.6608517}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 5.765200614929199, "logged_at": 1746615553.7072978}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 5.835336923599243, "logged_at": 1746615553.7640712}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 5.875706672668457, "logged_at": 1746615553.8132582}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 5.904123306274414, "logged_at": 1746615553.830086}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 5.975260019302368, "logged_at": 1746615553.9261196}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 6.048291444778442, "logged_at": 1746615553.9935844}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 6.057650804519653, "logged_at": 1746615554.001284}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 6.0824244022369385, "logged_at": 1746615554.0272236}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 6.141280174255371, "logged_at": 1746615554.0877619}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 6.146948575973511, "logged_at": 1746615554.0932536}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 7.147124767303467, "logged_at": 1746615555.1004653}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 7.503723621368408, "logged_at": 1746615555.4563706}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 9.221251249313354, "logged_at": 1746615557.1765969}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 1.0851778984069824, "logged_at": 1746615603.6684673}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.1692478656768799, "logged_at": 1746615603.749914}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.2440767288208008, "logged_at": 1746615603.8304949}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.262712001800537, "logged_at": 1746615603.8481042}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.5750889778137207, "logged_at": 1746615604.1465259}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.6552727222442627, "logged_at": 1746615604.2318678}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.7595629692077637, "logged_at": 1746615604.3341665}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.7651219367980957, "logged_at": 1746615604.3446753}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.8123948574066162, "logged_at": 1746615604.4021864}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.8319036960601807, "logged_at": 1746615604.4099221}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.9556465148925781, "logged_at": 1746615604.5466475}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 2.19681978225708, "logged_at": 1746615604.7807229}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 2.2285735607147217, "logged_at": 1746615604.8105876}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.4320552349090576, "logged_at": 1746615605.029574}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 2.8502728939056396, "logged_at": 1746615605.4483733}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 3.020007371902466, "logged_at": 1746615605.6103933}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.441802263259888, "logged_at": 1746615607.0461812}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 5.487194538116455, "logged_at": 1746615608.0881429}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 5.616642236709595, "logged_at": 1746615608.205365}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 5.633856296539307, "logged_at": 1746615608.2211058}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 5.647829294204712, "logged_at": 1746615608.2322633}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 5.69853401184082, "logged_at": 1746615608.290866}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 5.8817689418792725, "logged_at": 1746615608.4734004}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 5.983619213104248, "logged_at": 1746615608.5779269}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 6.007649660110474, "logged_at": 1746615608.6031992}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 6.042240619659424, "logged_at": 1746615608.6411777}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 6.075497627258301, "logged_at": 1746615608.6690967}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 6.082882881164551, "logged_at": 1746615608.6764984}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 6.462634801864624, "logged_at": 1746615609.0594144}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 6.53434944152832, "logged_at": 1746615609.1340032}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 6.986558437347412, "logged_at": 1746615609.5881777}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 7.580916404724121, "logged_at": 1746615610.1843793}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 7.697709560394287, "logged_at": 1746615610.3027833}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 7.817760467529297, "logged_at": 1746615610.4203138}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 7.929377317428589, "logged_at": 1746615610.5297196}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7181169986724854, "logged_at": 1746615644.5880907}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.8030171394348145, "logged_at": 1746615644.6748402}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.8419241905212402, "logged_at": 1746615644.7195692}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.8370094299316406, "logged_at": 1746615644.7215865}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.9022672176361084, "logged_at": 1746615644.7855349}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.9539611339569092, "logged_at": 1746615644.8265834}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.0892150402069092, "logged_at": 1746615644.9678893}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.094423770904541, "logged_at": 1746615644.9746015}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 1.3189456462860107, "logged_at": 1746615645.205331}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.35245943069458, "logged_at": 1746615645.2412508}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.5389986038208008, "logged_at": 1746615645.4359515}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.5416326522827148, "logged_at": 1746615645.4363391}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.5917716026306152, "logged_at": 1746615645.4587061}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.6096937656402588, "logged_at": 1746615645.4996166}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.6312861442565918, "logged_at": 1746615645.5132582}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.770397424697876, "logged_at": 1746615645.6656203}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.8481125831604004, "logged_at": 1746615645.7353745}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.8853473663330078, "logged_at": 1746615645.7733316}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.9088783264160156, "logged_at": 1746615645.8097801}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.954699993133545, "logged_at": 1746615645.8485832}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 2.0452704429626465, "logged_at": 1746615645.9367182}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 2.0737478733062744, "logged_at": 1746615645.9596364}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 2.129265546798706, "logged_at": 1746615646.0294642}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 2.2431094646453857, "logged_at": 1746615646.1351874}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 2.2734856605529785, "logged_at": 1746615646.1477764}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 2.2941834926605225, "logged_at": 1746615646.1895864}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.4102797508239746, "logged_at": 1746615646.3024933}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 2.4884421825408936, "logged_at": 1746615646.3792317}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 3.050325870513916, "logged_at": 1746615646.9533598}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 3.1369404792785645, "logged_at": 1746615647.0355136}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 3.517789125442505, "logged_at": 1746615647.4166658}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 3.694443941116333, "logged_at": 1746615647.5915573}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 3.724029541015625, "logged_at": 1746615647.6254387}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 4.442302703857422, "logged_at": 1746615648.3401654}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 5.101874589920044, "logged_at": 1746615649.0042138}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.7408270835876465, "logged_at": 1746615693.0049376}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.7869670391082764, "logged_at": 1746615693.0497053}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.8208699226379395, "logged_at": 1746615693.1033792}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.8499469757080078, "logged_at": 1746615693.123924}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.8619022369384766, "logged_at": 1746615693.1463602}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.9212439060211182, "logged_at": 1746615693.2067244}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.051222801208496, "logged_at": 1746615693.324427}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.0559108257293701, "logged_at": 1746615693.3375065}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.0503780841827393, "logged_at": 1746615693.3405647}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.0993494987487793, "logged_at": 1746615693.370864}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.0959358215332031, "logged_at": 1746615693.3719454}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 1.09537935256958, "logged_at": 1746615693.3750274}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.1145038604736328, "logged_at": 1746615693.3838315}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.108046054840088, "logged_at": 1746615693.3869236}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.1719176769256592, "logged_at": 1746615693.4443607}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.2007887363433838, "logged_at": 1746615693.4843147}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.2084996700286865, "logged_at": 1746615693.4948814}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.2160604000091553, "logged_at": 1746615693.5043569}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.2416396141052246, "logged_at": 1746615693.5188768}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.243495225906372, "logged_at": 1746615693.532614}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.252075433731079, "logged_at": 1746615693.5433836}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.2917838096618652, "logged_at": 1746615693.5794563}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.4288232326507568, "logged_at": 1746615693.718883}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.468125820159912, "logged_at": 1746615693.763627}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.5461063385009766, "logged_at": 1746615693.8381634}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.5637717247009277, "logged_at": 1746615693.8411696}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.592010259628296, "logged_at": 1746615693.866796}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.6599562168121338, "logged_at": 1746615693.947045}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.7173798084259033, "logged_at": 1746615693.9980097}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.750044345855713, "logged_at": 1746615694.0394351}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.842149257659912, "logged_at": 1746615694.1350899}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 2.135105848312378, "logged_at": 1746615694.4287996}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.1611328125, "logged_at": 1746615694.4560058}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.392134666442871, "logged_at": 1746615694.6881177}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.9539859294891357, "logged_at": 1746615695.2482576}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.299790620803833, "logged_at": 1746615737.7895675}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.3241877555847168, "logged_at": 1746615737.8063996}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.3094515800476074, "logged_at": 1746615737.8101857}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.3298361301422119, "logged_at": 1746615737.8209047}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.3351168632507324, "logged_at": 1746615737.8319972}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 0.32854795455932617, "logged_at": 1746615737.8368027}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.3398280143737793, "logged_at": 1746615737.8450441}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.3582589626312256, "logged_at": 1746615737.8454292}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.35634493827819824, "logged_at": 1746615737.8484213}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 0.341339111328125, "logged_at": 1746615737.853124}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.3587961196899414, "logged_at": 1746615737.858699}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.36706113815307617, "logged_at": 1746615737.8624585}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 0.35178709030151367, "logged_at": 1746615737.8630462}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.3774561882019043, "logged_at": 1746615737.8765626}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.4016847610473633, "logged_at": 1746615737.8819156}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.37989258766174316, "logged_at": 1746615737.882333}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.3981187343597412, "logged_at": 1746615737.8912816}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.4077284336090088, "logged_at": 1746615737.9039729}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.41754961013793945, "logged_at": 1746615737.9073446}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 0.4037313461303711, "logged_at": 1746615737.9164453}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.4191305637359619, "logged_at": 1746615737.9165812}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 0.4210684299468994, "logged_at": 1746615737.9224796}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 0.41719627380371094, "logged_at": 1746615737.9287627}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 0.4226493835449219, "logged_at": 1746615737.932169}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.4472157955169678, "logged_at": 1746615737.9375594}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.45134639739990234, "logged_at": 1746615737.9456143}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.4530904293060303, "logged_at": 1746615737.9458575}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.45495080947875977, "logged_at": 1746615737.952989}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 0.44763898849487305, "logged_at": 1746615737.9549978}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 0.46565866470336914, "logged_at": 1746615737.9691434}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.471698522567749, "logged_at": 1746615737.976128}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 0.48104000091552734, "logged_at": 1746615737.987142}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.49054694175720215, "logged_at": 1746615737.9936583}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 0.5115494728088379, "logged_at": 1746615738.0184355}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 0.5551173686981201, "logged_at": 1746615738.0638723}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.25927114486694336, "logged_at": 1746615783.9762714}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.3576323986053467, "logged_at": 1746615784.098185}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.3568685054779053, "logged_at": 1746615784.1034293}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.3699495792388916, "logged_at": 1746615784.103827}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.3720390796661377, "logged_at": 1746615784.1040735}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.37957763671875, "logged_at": 1746615784.104207}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 0.36605358123779297, "logged_at": 1746615784.1053097}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 0.3625147342681885, "logged_at": 1746615784.1056054}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.3690476417541504, "logged_at": 1746615784.1059139}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.4404294490814209, "logged_at": 1746615784.1716366}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.4523754119873047, "logged_at": 1746615784.183171}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.4410398006439209, "logged_at": 1746615784.1829553}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.463242769241333, "logged_at": 1746615784.1835732}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.46052074432373047, "logged_at": 1746615784.1839573}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.44646334648132324, "logged_at": 1746615784.184219}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.4622485637664795, "logged_at": 1746615784.1847034}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.45923829078674316, "logged_at": 1746615784.1851578}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 0.6222400665283203, "logged_at": 1746615784.3756425}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 0.634814977645874, "logged_at": 1746615784.3787386}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.6434459686279297, "logged_at": 1746615784.3814213}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.6356186866760254, "logged_at": 1746615784.3826792}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.6393387317657471, "logged_at": 1746615784.384098}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 0.7919442653656006, "logged_at": 1746615784.5432222}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 0.7965059280395508, "logged_at": 1746615784.546928}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.8215658664703369, "logged_at": 1746615784.5493817}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.8028562068939209, "logged_at": 1746615784.5512328}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.8141522407531738, "logged_at": 1746615784.5516403}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.8067255020141602, "logged_at": 1746615784.5518937}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 0.8079707622528076, "logged_at": 1746615784.5520852}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 0.8049747943878174, "logged_at": 1746615784.5521839}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 0.800640344619751, "logged_at": 1746615784.552355}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 0.8017904758453369, "logged_at": 1746615784.5609505}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 2.1353659629821777, "logged_at": 1746615785.8826761}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 2.1565749645233154, "logged_at": 1746615785.8829296}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 2.1373424530029297, "logged_at": 1746615785.8830507}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 1.1476619243621826, "logged_at": 1746615789.7438302}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.3197128772735596, "logged_at": 1746615789.901053}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.3646869659423828, "logged_at": 1746615789.9575944}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.439267873764038, "logged_at": 1746615790.0366392}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.500870704650879, "logged_at": 1746615790.0852783}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.519341230392456, "logged_at": 1746615790.1065216}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.5295052528381348, "logged_at": 1746615790.1084964}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.5744984149932861, "logged_at": 1746615790.1756086}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 1.6801748275756836, "logged_at": 1746615790.2820725}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.8138461112976074, "logged_at": 1746615790.40561}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.8874149322509766, "logged_at": 1746615790.491747}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.9127347469329834, "logged_at": 1746615790.4995396}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 2.011178493499756, "logged_at": 1746615790.6182585}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 2.154264211654663, "logged_at": 1746615790.7524297}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 2.797839879989624, "logged_at": 1746615791.3979104}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 2.91031551361084, "logged_at": 1746615791.5003543}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 3.434793710708618, "logged_at": 1746615792.0275283}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 3.7376415729522705, "logged_at": 1746615792.3285422}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 4.222886562347412, "logged_at": 1746615792.8215969}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 4.297762632369995, "logged_at": 1746615792.9029858}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7821986675262451, "logged_at": 1746615910.5728555}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.856560230255127, "logged_at": 1746615910.6566472}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.9057385921478271, "logged_at": 1746615910.699811}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.1136720180511475, "logged_at": 1746615910.910987}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.1655685901641846, "logged_at": 1746615910.9757993}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.2528612613677979, "logged_at": 1746615911.056866}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.290579080581665, "logged_at": 1746615911.0745683}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.3367648124694824, "logged_at": 1746615911.1241746}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.3223187923431396, "logged_at": 1746615911.1255052}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.3906567096710205, "logged_at": 1746615911.1992273}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.4033873081207275, "logged_at": 1746615911.2128088}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.4830248355865479, "logged_at": 1746615911.2819762}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.5712132453918457, "logged_at": 1746615911.3691282}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.592221736907959, "logged_at": 1746615911.3940675}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.6255011558532715, "logged_at": 1746615911.4206502}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.7751531600952148, "logged_at": 1746615911.56437}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.806614875793457, "logged_at": 1746615911.5999384}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.8825256824493408, "logged_at": 1746615911.6851265}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.926743507385254, "logged_at": 1746615911.732898}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 1.9855453968048096, "logged_at": 1746615911.786289}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 2.151244878768921, "logged_at": 1746615911.9439692}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 2.170865058898926, "logged_at": 1746615911.9701517}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 2.888775110244751, "logged_at": 1746615912.684735}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 2.933887481689453, "logged_at": 1746615912.738415}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 3.30492901802063, "logged_at": 1746615913.1100428}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 3.406358480453491, "logged_at": 1746615913.2225056}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 3.7818763256073, "logged_at": 1746615913.5959082}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 3.852729320526123, "logged_at": 1746615913.669821}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.2640275955200195, "logged_at": 1746615914.0794969}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 5.034253120422363, "logged_at": 1746615914.842122}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 8.07175350189209, "logged_at": 1746615917.878059}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 8.776830911636353, "logged_at": 1746615918.5733652}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 10.347360610961914, "logged_at": 1746615920.1583586}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 10.60097885131836, "logged_at": 1746615920.4077034}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 15.140815496444702, "logged_at": 1746615924.9587216}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.5128693580627441, "logged_at": 1746616018.0195425}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.5143322944641113, "logged_at": 1746616018.0327332}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.5661518573760986, "logged_at": 1746616018.0771825}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.5715081691741943, "logged_at": 1746616018.080056}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.5829746723175049, "logged_at": 1746616018.0861533}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.6095924377441406, "logged_at": 1746616018.110781}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.6503372192382812, "logged_at": 1746616018.1630566}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7803537845611572, "logged_at": 1746616018.2882419}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.796032190322876, "logged_at": 1746616018.2936797}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.854945182800293, "logged_at": 1746616018.3571799}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.8899087905883789, "logged_at": 1746616018.4049723}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 0.9186782836914062, "logged_at": 1746616018.4452639}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.2166709899902344, "logged_at": 1746616018.7213418}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.214519739151001, "logged_at": 1746616018.7372637}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.3099005222320557, "logged_at": 1746616018.8303661}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.3532967567443848, "logged_at": 1746616018.8791482}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.3663055896759033, "logged_at": 1746616018.882024}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 1.3671457767486572, "logged_at": 1746616018.894883}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.4330267906188965, "logged_at": 1746616018.9595187}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.5576324462890625, "logged_at": 1746616019.0670247}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.9235177040100098, "logged_at": 1746616019.4395213}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.7482309341430664, "logged_at": 1746616019.4700382}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.979724645614624, "logged_at": 1746616019.4934464}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 2.0054078102111816, "logged_at": 1746616019.5172927}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 2.041079521179199, "logged_at": 1746616019.5562198}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 2.0462610721588135, "logged_at": 1746616019.5565975}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 2.299602746963501, "logged_at": 1746616019.8208318}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.4215407371520996, "logged_at": 1746616019.9406283}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 2.759080648422241, "logged_at": 1746616020.2787983}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 2.924656629562378, "logged_at": 1746616020.4498348}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 0.7757997512817383, "logged_at": 1746616020.5968986}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.0610520839691162, "logged_at": 1746616020.6200607}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.1793172359466553, "logged_at": 1746616020.6970334}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 3.330579996109009, "logged_at": 1746616020.8547792}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 1.5619628429412842, "logged_at": 1746616021.0020459}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.515474319458008, "logged_at": 1746616021.0331707}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.5490062236785889, "logged_at": 1746616021.0429647}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.4980299472808838, "logged_at": 1746616021.0550115}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 0.7933919429779053, "logged_at": 1746616021.0726016}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 3.911473512649536, "logged_at": 1746616021.433573}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 4.165236234664917, "logged_at": 1746616021.678457}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 4.258376598358154, "logged_at": 1746616021.7754922}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 2.28517484664917, "logged_at": 1746616022.2261531}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.791862487792969, "logged_at": 1746616022.3153756}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.228877067565918, "logged_at": 1746616023.004817}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.9506213665008545, "logged_at": 1746616023.384468}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 2.487949848175049, "logged_at": 1746616023.5214295}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.0031416416168213, "logged_at": 1746616023.682092}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 3.7749075889587402, "logged_at": 1746616024.6301117}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 3.331207036972046, "logged_at": 1746616025.6470928}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.7643818855285645, "logged_at": 1746616060.4113183}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.826730489730835, "logged_at": 1746616060.4768076}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.8193256855010986, "logged_at": 1746616060.480241}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.8456876277923584, "logged_at": 1746616060.4881465}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.9596123695373535, "logged_at": 1746616060.623066}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.9668774604797363, "logged_at": 1746616060.6234248}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.004154920578003, "logged_at": 1746616060.6638076}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 1.0906596183776855, "logged_at": 1746616060.7461963}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 1.1091375350952148, "logged_at": 1746616060.7676687}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.1311759948730469, "logged_at": 1746616060.7880924}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.291133165359497, "logged_at": 1746616060.9486177}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.3509223461151123, "logged_at": 1746616061.013433}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 1.3623297214508057, "logged_at": 1746616061.0168195}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.3583588600158691, "logged_at": 1746616061.0248752}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.451364517211914, "logged_at": 1746616061.0987546}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.5278651714324951, "logged_at": 1746616061.1895132}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 1.5922691822052002, "logged_at": 1746616061.2561054}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 1.6320345401763916, "logged_at": 1746616061.2846918}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.6940484046936035, "logged_at": 1746616061.3542905}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 1.7038226127624512, "logged_at": 1746616061.3695767}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.8007586002349854, "logged_at": 1746616061.4653988}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 1.8960201740264893, "logged_at": 1746616061.5663235}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 1.9391958713531494, "logged_at": 1746616061.6043763}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 2.041649341583252, "logged_at": 1746616061.7095122}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 2.1315464973449707, "logged_at": 1746616061.798729}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 3.2268049716949463, "logged_at": 1746616062.8962042}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 3.4004979133605957, "logged_at": 1746616063.069099}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 3.663520574569702, "logged_at": 1746616063.333568}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 4.017802953720093, "logged_at": 1746616063.6939497}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 4.5348289012908936, "logged_at": 1746616064.2090719}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 4.836488723754883, "logged_at": 1746616064.5104835}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 5.531997442245483, "logged_at": 1746616065.2053003}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 5.593488454818726, "logged_at": 1746616065.27023}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 5.8871331214904785, "logged_at": 1746616065.5620313}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 6.762234449386597, "logged_at": 1746616066.4341297}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.6235799789428711, "logged_at": 1746616109.3669472}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.6271610260009766, "logged_at": 1746616109.3737028}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.658660888671875, "logged_at": 1746616109.3875482}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.6459670066833496, "logged_at": 1746616109.3902225}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.655128002166748, "logged_at": 1746616109.3931775}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.6934435367584229, "logged_at": 1746616109.4268658}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.6997628211975098, "logged_at": 1746616109.4309237}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.6889097690582275, "logged_at": 1746616109.434636}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 0.7263901233673096, "logged_at": 1746616109.451993}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.7162322998046875, "logged_at": 1746616109.4692073}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.7298545837402344, "logged_at": 1746616109.472422}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.7363135814666748, "logged_at": 1746616109.472785}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.7715318202972412, "logged_at": 1746616109.5082552}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 0.7651114463806152, "logged_at": 1746616109.5188239}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7872941493988037, "logged_at": 1746616109.5382962}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.8201751708984375, "logged_at": 1746616109.575456}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.8321747779846191, "logged_at": 1746616109.5842988}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.8528022766113281, "logged_at": 1746616109.5944214}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.8582804203033447, "logged_at": 1746616109.607}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 0.8579654693603516, "logged_at": 1746616109.616178}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.8742666244506836, "logged_at": 1746616109.6241314}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.8827872276306152, "logged_at": 1746616109.646447}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 0.9855759143829346, "logged_at": 1746616109.7400923}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 0.9946119785308838, "logged_at": 1746616109.7525306}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 1.0550565719604492, "logged_at": 1746616109.8110764}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 1.1451528072357178, "logged_at": 1746616109.901983}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 1.1773567199707031, "logged_at": 1746616109.9374282}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.1777443885803223, "logged_at": 1746616109.943525}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.2616891860961914, "logged_at": 1746616110.0227003}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 1.3111627101898193, "logged_at": 1746616110.0603485}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.3243560791015625, "logged_at": 1746616110.087016}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 1.4225854873657227, "logged_at": 1746616110.1632893}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 1.4704148769378662, "logged_at": 1746616110.232602}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 1.7883856296539307, "logged_at": 1746616110.5535111}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 2.0292303562164307, "logged_at": 1746616110.7938845}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 0.290388822555542, "logged_at": 1746616157.784074}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 0.3101162910461426, "logged_at": 1746616157.7944205}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 0.3326547145843506, "logged_at": 1746616157.7952442}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 0.369952917098999, "logged_at": 1746616157.878864}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 0.821892261505127, "logged_at": 1746616158.4488673}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 1.2582271099090576, "logged_at": 1746616158.9831185}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 1.1192188262939453, "logged_at": 1746617016.8549533}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 1.180879831314087, "logged_at": 1746617016.9215472}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 1.2736294269561768, "logged_at": 1746617017.0182176}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 1.289891004562378, "logged_at": 1746617017.0273378}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 1.3760395050048828, "logged_at": 1746617017.1176698}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 1.4452564716339111, "logged_at": 1746617017.1957374}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 1.5136299133300781, "logged_at": 1746617017.2571163}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 1.6465909481048584, "logged_at": 1746617017.3953238}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.7297594547271729, "logged_at": 1746617017.4609551}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 1.7253880500793457, "logged_at": 1746617017.4716117}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 1.798379898071289, "logged_at": 1746617017.5452747}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 1.8225302696228027, "logged_at": 1746617017.5704336}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 1.8447778224945068, "logged_at": 1746617017.596644}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 2.007429599761963, "logged_at": 1746617017.7627165}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 2.1799075603485107, "logged_at": 1746617017.9335253}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 2.413191080093384, "logged_at": 1746617018.145089}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 2.406050443649292, "logged_at": 1746617018.1664593}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 2.4935131072998047, "logged_at": 1746617018.2496798}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 2.785395860671997, "logged_at": 1746617018.5241861}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 2.965956211090088, "logged_at": 1746617018.7170725}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 3.0121347904205322, "logged_at": 1746617018.7577598}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 3.1503243446350098, "logged_at": 1746617018.9081452}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 3.3312385082244873, "logged_at": 1746617019.0883162}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 3.699528455734253, "logged_at": 1746617019.45883}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 3.766172409057617, "logged_at": 1746617019.5187533}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 4.37231183052063, "logged_at": 1746617020.115066}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 4.512630939483643, "logged_at": 1746617020.262126}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 5.526366710662842, "logged_at": 1746617021.2950275}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 6.304810285568237, "logged_at": 1746617022.0695643}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 7.4998414516448975, "logged_at": 1746617023.2583833}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 37.38192439079285, "logged_at": 1746617053.147578}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 54.88931202888489, "logged_at": 1746617070.6556208}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 60.25096035003662, "logged_at": 1746617076.0177507}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 66.00684571266174, "logged_at": 1746617081.7748435}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 73.83858585357666, "logged_at": 1746617089.605931}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 10.220225095748901, "logged_at": 1746617123.86748}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 11.703642845153809, "logged_at": 1746617125.3565376}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 15.882418632507324, "logged_at": 1746617129.5267422}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 16.791629552841187, "logged_at": 1746617130.443214}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 17.679290056228638, "logged_at": 1746617131.3272586}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 17.942161321640015, "logged_at": 1746617131.5944679}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 18.31268835067749, "logged_at": 1746617131.9616737}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 21.08007550239563, "logged_at": 1746617134.7363667}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 23.420217037200928, "logged_at": 1746617137.0589254}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 23.971248149871826, "logged_at": 1746617137.6166246}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 24.440824508666992, "logged_at": 1746617138.081963}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 24.51569652557373, "logged_at": 1746617138.1692452}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 26.431262254714966, "logged_at": 1746617140.0809193}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 28.84232234954834, "logged_at": 1746617142.5015564}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 28.977850914001465, "logged_at": 1746617142.6473246}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 31.861682653427124, "logged_at": 1746617145.512025}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 32.40552020072937, "logged_at": 1746617146.06027}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 33.209500551223755, "logged_at": 1746617146.8678484}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 36.41814470291138, "logged_at": 1746617150.0820286}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 37.1409752368927, "logged_at": 1746617150.7832873}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 37.974294900894165, "logged_at": 1746617151.6396384}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 38.0259051322937, "logged_at": 1746617151.6864889}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 41.84288930892944, "logged_at": 1746617155.497026}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 48.93507981300354, "logged_at": 1746617162.598013}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 50.099183320999146, "logged_at": 1746617163.7566612}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 51.041321754455566, "logged_at": 1746617164.7099254}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 51.73870778083801, "logged_at": 1746617165.400224}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 52.17357516288757, "logged_at": 1746617165.8402119}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 55.42245125770569, "logged_at": 1746617169.0623248}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 60.802401065826416, "logged_at": 1746617174.4684842}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 63.59578776359558, "logged_at": 1746617177.2580793}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 67.17362809181213, "logged_at": 1746617180.8368044}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 79.350270986557, "logged_at": 1746617193.0058334}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 97.17264199256897, "logged_at": 1746617210.8406131}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 115.98776006698608, "logged_at": 1746617412.5662067}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 6.530991077423096, "logged_at": 1746617451.6786404}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 7.700685262680054, "logged_at": 1746617452.821575}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 8.713819980621338, "logged_at": 1746617453.8511913}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 8.914368152618408, "logged_at": 1746617454.04544}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 9.048585653305054, "logged_at": 1746617454.1891236}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 9.115166664123535, "logged_at": 1746617454.2634225}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 9.497799158096313, "logged_at": 1746617454.6303399}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 9.545353174209595, "logged_at": 1746617454.696667}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 9.98015809059143, "logged_at": 1746617455.1032944}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 9.972677946090698, "logged_at": 1746617455.1194184}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 10.058048009872437, "logged_at": 1746617455.1878052}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 10.507381677627563, "logged_at": 1746617455.6458497}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 10.646095514297485, "logged_at": 1746617455.79793}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 11.535223245620728, "logged_at": 1746617456.6670418}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 12.139500141143799, "logged_at": 1746617457.288275}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 12.3700590133667, "logged_at": 1746617457.4886122}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 12.41624927520752, "logged_at": 1746617457.550228}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 12.591368198394775, "logged_at": 1746617457.7173982}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 12.830060243606567, "logged_at": 1746617457.9635046}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 12.900238275527954, "logged_at": 1746617458.029182}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 13.070340394973755, "logged_at": 1746617458.206089}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 13.349894523620605, "logged_at": 1746617458.5044186}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 13.498395204544067, "logged_at": 1746617458.6515093}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 13.52929973602295, "logged_at": 1746617458.6683433}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 14.079202890396118, "logged_at": 1746617459.2293563}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 14.618116617202759, "logged_at": 1746617459.7547884}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 16.20267367362976, "logged_at": 1746617461.3176043}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 16.30869698524475, "logged_at": 1746617461.443564}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 16.87584686279297, "logged_at": 1746617462.021658}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 17.140807151794434, "logged_at": 1746617462.2805088}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 18.474040508270264, "logged_at": 1746617463.6278298}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 19.187220573425293, "logged_at": 1746617464.3378398}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 21.404088258743286, "logged_at": 1746617466.5535247}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 24.418015956878662, "logged_at": 1746617469.6362927}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 24.97970676422119, "logged_at": 1746617470.1322184}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Key changes:", "duration": 3.318117141723633, "logged_at": 1746617519.7115536}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "It doesn't matter now.", "duration": 3.628156900405884, "logged_at": 1746617520.0329866}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 3.8009185791015625, "logged_at": 1746617520.1966162}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 4.367016315460205, "logged_at": 1746617520.766444}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 5.47055459022522, "logged_at": 1746617521.8784275}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 5.665018320083618, "logged_at": 1746617522.0677578}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 6.1406824588775635, "logged_at": 1746617522.535054}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 6.129136323928833, "logged_at": 1746617522.5417104}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 6.410813808441162, "logged_at": 1746617522.8082092}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "And yet - and yet - that was the very problem, the crux of the issue, the source of all that conflict: Their inability to agree upon anything.", "duration": 6.874240398406982, "logged_at": 1746617523.2827685}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 6.9099485874176025, "logged_at": 1746617523.2919726}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 6.882727861404419, "logged_at": 1746617523.2944934}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Top 1% Commenter", "duration": 6.956147909164429, "logged_at": 1746617523.3408668}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 7.796895265579224, "logged_at": 1746617524.2080944}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 8.789555788040161, "logged_at": 1746617525.1997643}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 9.123009443283081, "logged_at": 1746617525.541512}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Python enumerate() Function", "duration": 9.191875219345093, "logged_at": 1746617525.5750997}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 9.277782917022705, "logged_at": 1746617525.6791618}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 9.30793023109436, "logged_at": 1746617525.724728}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 9.336921453475952, "logged_at": 1746617525.7440188}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 9.76997709274292, "logged_at": 1746617526.170439}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 9.821200847625732, "logged_at": 1746617526.227479}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 10.0520920753479, "logged_at": 1746617526.47134}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 10.375866889953613, "logged_at": 1746617526.7616649}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 10.680538177490234, "logged_at": 1746617527.0841894}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 11.46826457977295, "logged_at": 1746617527.8814917}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In a quiet forest, where the sun peeked through the trees like golden butter, Ellie the Elephant was not happy. Ellie couldn't find her hat! She asked the squirrels, who were too busy playing tag. She asked the birds, but they were too busy singing. At last, it was Mister Turtle who found it while munching a pile of autumn leaves.", "duration": 12.214913606643677, "logged_at": 1746617528.6288652}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 13.210487842559814, "logged_at": 1746617529.6078203}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 13.75748062133789, "logged_at": 1746617530.163059}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 14.81558346748352, "logged_at": 1746617531.2313662}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 15.692781925201416, "logged_at": 1746617532.1128511}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 16.67154598236084, "logged_at": 1746617533.0865433}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 20.704092741012573, "logged_at": 1746617537.094283}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 35.26582479476929, "logged_at": 1746617551.675207}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 38.82525944709778, "logged_at": 1746617555.2430146}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Minimum Viable Blog", "duration": 0.3126680850982666, "logged_at": 1746617625.7070668}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Eggs US \u2013 Price \u2013 Chart", "duration": 0.3776280879974365, "logged_at": 1746617625.7515333}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "Check important info.", "duration": 0.4761693477630615, "logged_at": 1746617625.886105}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "The best translator is a hybrid translator", "duration": 0.7854399681091309, "logged_at": 1746617626.1880748}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "This isn\u2019t what I ordered.", "duration": 0.3024899959564209, "logged_at": 1746620228.273845}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "Will this be available to download on GitHub?", "duration": 0.518770694732666, "logged_at": 1746620228.4849093}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "And a few things I think would be cool, but aren't core to the idea:", "duration": 0.5062077045440674, "logged_at": 1746620228.4950707}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "ratio + L + cope + seethe", "duration": 1.057978630065918, "logged_at": 1746620229.0006132}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "8 FUCKING IRONSHIPS (& gunboat friends)", "duration": 0.31107068061828613, "logged_at": 1746620344.8710175}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "The risk was calculated, but the variables were bollocks.", "duration": 0.40560412406921387, "logged_at": 1746620345.0105321}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "idea: bounce it back and forth with wrapped encryption from a far probe.", "duration": 0.45798301696777344, "logged_at": 1746620345.0432556}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "Reduced temperature of translations based on preliminary results from translation research", "duration": 0.43538618087768555, "logged_at": 1746620345.04391}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples", "duration": 1.1993439197540283, "logged_at": 1746620349.3062391}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "The fact that you got a positive-sloping line out at all from the regression has to do more with the positions of the outliers than anything else.", "duration": 0.9229006767272949, "logged_at": 1746620349.957887}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "This article reminds me of another I read first here, 'Reality Has A Surprising Amount of Detail' by John Salvatier. At first blush 3D printing seems easy, but especially with smaller parts that might go through many duty cycles it's anything but. I'm going to have to do more than skim this, I think this one is worth multiple reads over many days to really absorb the densely packed information.", "duration": 0.9777154922485352, "logged_at": 1746620351.0284448}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "At father's command he'd had a crown made, a simple gold circlet.", "duration": 0.5966050624847412, "logged_at": 1746620353.529769}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "They then run stepwise regression to determine variance contributions, seemingly ignoring their earlier results, and this leads to almost no contribution from numeracy. Why? Because they have ~10% shared variance and stepwise regression is greedy - will just take whatever you give it first. I can't mention this part enough. If you got a second, very similar language test, and added it to the model, you would _also_ find it has almost no unique variance added. Every thing they measure is incredibly noisy and they do not once attempt to deal with this. Human based reviewers, time-to-completion, etc. p-value for \"language learning is more significant than numeracy\" on the values they give (Steiger test) gives 0.772. Utterly insignificant.", "duration": 1.5817317962646484, "logged_at": 1746620353.63988}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics.", "duration": 1.0559430122375488, "logged_at": 1746620356.0668163}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "The dev feels that there won't really be a point of adding a new vehicle that can only do the same things as the other existing ones.", "duration": 0.6676805019378662, "logged_at": 1746620356.7009737}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "if you zoom in on the first table on the right, you can see people pooling their coins together to pay, because the card readers don't work.", "duration": 0.4878973960876465, "logged_at": 1746620356.8155136}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "Try refreshing the page.", "duration": 0.3516073226928711, "logged_at": 1746620391.7330549}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "This reads like an LLM wrote it.", "duration": 0.4809396266937256, "logged_at": 1746620391.8217638}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "The Nuenki browser extension finds sentences in the websites you visit.", "duration": 0.7829380035400391, "logged_at": 1746620392.137079}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "Pursuant to Article 8(C) of Directive 121, and in light of the recommendations of the consultion on inter-departmental affairs issued by the Department of Departmental Affairs, the Commission has decided to consult to adopt a preliminary position regarding the regulation of meat. In accordance with Regulation 7(B), the preliminary position will be subject to public consultation pursuant with the Public Consultation Act of 1988.", "duration": 1.0315985679626465, "logged_at": 1746620402.6309307}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "I built that, and made it open source. It turns out that you can! While its coherence is slightly lower than its peers (more on that in a moment), it is the most idiomatic model while also being far more consistent, with a much lower standard deviation across all three metrics. It works by taking the top 3-4 models for a given language (based on this research), translating with them, then having a judge model (currently redacted) consider the strengths and weaknesses of each translation and merge them together in an idiomatic way.", "duration": 3.2715649604797363, "logged_at": 1746620403.8726583}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "The objective, of course, was never to solve the actual problem: No, the real reason they had gone through all of that bother was to *appear* to be working on the issue, never mind actually solving it.", "duration": 4.150993585586548, "logged_at": 1746620404.7995327}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "It is in this case that we deploy the Four Stage Strategy. First: Nothing is going to happen. Second: Yes, something may in fact happen, but we shouldn't do anything about it. Third: Yes, something is happening, but there's nothing we *can* do! Third: Alright, maybe there was something we could do, but it's too late now. Oops.", "duration": 0.8796465396881104, "logged_at": 1746620409.6544898}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "Hell, just the fact that there's 3 officer uniforms in one picture is funny enough to me.", "duration": 0.46451830863952637, "logged_at": 1746620410.2422068}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "The people who get what they want in these situations are the ones who are prepared to behave sufficiently unreasonably, and with sufficient stubbornness. This is a second order consequence of 'unaccountability' that Davies misses. For the customer, or the object of the system, it incentivises unpleasant behaviour - as unpleasant as possible - because it's often the only way to trigger the exception / escalation / special case, and get what you want.", "duration": 1.4048559665679932, "logged_at": 1746620420.2460618}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 4.435782194137573, "logged_at": 1746622209.27515}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 4.431321859359741, "logged_at": 1746622209.278565}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 4.544978141784668, "logged_at": 1746622209.3968558}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 4.828845500946045, "logged_at": 1746622209.678572}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 4.875123739242554, "logged_at": 1746622209.7160857}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 5.159952163696289, "logged_at": 1746622210.0134807}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.832855224609375, "logged_at": 1746622210.1118624}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 5.270482778549194, "logged_at": 1746622210.1319823}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 5.378253936767578, "logged_at": 1746622210.2361531}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 0.8443000316619873, "logged_at": 1746622210.2415376}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 5.407145023345947, "logged_at": 1746622210.262718}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.1685433387756348, "logged_at": 1746622210.444122}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 5.628755569458008, "logged_at": 1746622210.4721272}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 0.7609803676605225, "logged_at": 1746622210.4773817}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 0.8134377002716064, "logged_at": 1746622210.4925928}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 5.658877611160278, "logged_at": 1746622210.5070918}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 5.707814931869507, "logged_at": 1746622210.5717945}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 5.910032749176025, "logged_at": 1746622210.7751606}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 0.7889716625213623, "logged_at": 1746622210.8028708}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 6.142658472061157, "logged_at": 1746622211.0103862}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 6.204877138137817, "logged_at": 1746622211.0417109}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 0.8402085304260254, "logged_at": 1746622211.10322}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 0.8907735347747803, "logged_at": 1746622211.1272373}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.7352211475372314, "logged_at": 1746622211.2079515}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 1.1643846035003662, "logged_at": 1746622211.296629}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 0.8651440143585205, "logged_at": 1746622211.3725264}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 7.111527442932129, "logged_at": 1746622211.9744377}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 1.4669506549835205, "logged_at": 1746622212.0391176}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 1.3835160732269287, "logged_at": 1746622212.159095}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.1202712059020996, "logged_at": 1746622212.162412}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 1.2030572891235352, "logged_at": 1746622212.2137642}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 7.7806525230407715, "logged_at": 1746622212.6393433}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 1.2433807849884033, "logged_at": 1746622213.2181232}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 1.7775781154632568, "logged_at": 1746622214.4172032}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 9.926214933395386, "logged_at": 1746622214.782411}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 10.895009756088257, "logged_at": 1746622215.7480183}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.607776403427124, "logged_at": 1746622216.3905563}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 11.630600690841675, "logged_at": 1746622216.4850893}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 0.9843599796295166, "logged_at": 1746622217.4697719}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 2.3915979862213135, "logged_at": 1746622218.1406367}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 16.3922221660614, "logged_at": 1746622221.2369473}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 0.7706384658813477, "logged_at": 1746622222.007905}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 19.712157726287842, "logged_at": 1746622224.5831516}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 19.89926815032959, "logged_at": 1746622224.7651432}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 20.048101902008057, "logged_at": 1746622224.9175158}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 1.950927972793579, "logged_at": 1746622226.8688717}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 2.7463250160217285, "logged_at": 1746622227.3299022}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 4.126176118850708, "logged_at": 1746622228.8916156}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.8991632461547852, "logged_at": 1746622283.9926763}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 0.9670820236206055, "logged_at": 1746622284.0767272}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.9793658256530762, "logged_at": 1746622284.0885704}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 1.014739990234375, "logged_at": 1746622284.1114988}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 1.0483372211456299, "logged_at": 1746622284.1661346}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 1.0769445896148682, "logged_at": 1746622284.184316}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 1.087615966796875, "logged_at": 1746622284.1983368}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.1173558235168457, "logged_at": 1746622284.2050412}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 1.093895673751831, "logged_at": 1746622284.2169166}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 1.1528894901275635, "logged_at": 1746622284.2791562}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 1.1943891048431396, "logged_at": 1746622284.307366}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 1.2349255084991455, "logged_at": 1746622284.3570814}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 1.3458712100982666, "logged_at": 1746622284.4312603}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 1.3500699996948242, "logged_at": 1746622284.4498136}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.460423469543457, "logged_at": 1746622284.5558655}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 1.5212481021881104, "logged_at": 1746622284.6370027}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.5485098361968994, "logged_at": 1746622284.6684327}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 1.609645128250122, "logged_at": 1746622284.734744}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 2.474280595779419, "logged_at": 1746622285.5930188}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 2.4930202960968018, "logged_at": 1746622285.6078713}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 3.452782154083252, "logged_at": 1746622286.5740943}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 3.5052542686462402, "logged_at": 1746622286.6296918}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 4.563825845718384, "logged_at": 1746622287.774831}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 4.816024303436279, "logged_at": 1746622287.9441247}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.9554498195648193, "logged_at": 1746622343.383012}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 1.0975303649902344, "logged_at": 1746622343.534106}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 1.0990171432495117, "logged_at": 1746622343.5344546}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 1.1327733993530273, "logged_at": 1746622343.5752294}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 1.1816678047180176, "logged_at": 1746622343.61924}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 1.2145891189575195, "logged_at": 1746622343.6436427}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 1.246401071548462, "logged_at": 1746622343.676932}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.288135051727295, "logged_at": 1746622343.7195811}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 1.3988697528839111, "logged_at": 1746622343.8398223}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.4359474182128906, "logged_at": 1746622343.8682075}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 1.5577788352966309, "logged_at": 1746622343.9994907}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 1.605025291442871, "logged_at": 1746622344.043114}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 1.722092628479004, "logged_at": 1746622344.1620631}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 1.76707124710083, "logged_at": 1746622344.2064564}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 1.9661180973052979, "logged_at": 1746622344.4144363}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 2.1337931156158447, "logged_at": 1746622344.580371}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 2.263740301132202, "logged_at": 1746622344.7084372}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 2.484274387359619, "logged_at": 1746622344.929058}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 2.636776924133301, "logged_at": 1746622345.0800014}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 4.89272665977478, "logged_at": 1746622347.345172}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 5.913434028625488, "logged_at": 1746622348.350221}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 6.959002733230591, "logged_at": 1746622349.406634}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 7.685187816619873, "logged_at": 1746622350.1346786}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 15.516288757324219, "logged_at": 1746622357.966706}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 2.0921859741210938, "logged_at": 1746622403.9319925}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 2.3724589347839355, "logged_at": 1746622404.2173474}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 2.7502646446228027, "logged_at": 1746622404.5821965}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 2.979769468307495, "logged_at": 1746622404.813015}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 3.0453941822052, "logged_at": 1746622404.8817515}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 3.9729666709899902, "logged_at": 1746622405.825425}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 4.01556921005249, "logged_at": 1746622405.8628569}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 4.087749719619751, "logged_at": 1746622405.9230669}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 4.163135051727295, "logged_at": 1746622406.0086296}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 4.356961965560913, "logged_at": 1746622406.1940825}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 5.563128709793091, "logged_at": 1746622407.4074197}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 5.822479486465454, "logged_at": 1746622407.664743}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 6.29977822303772, "logged_at": 1746622408.1459565}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 8.258519649505615, "logged_at": 1746622410.1022205}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 8.588840007781982, "logged_at": 1746622410.4403143}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 8.791941404342651, "logged_at": 1746622410.6227417}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 8.946887493133545, "logged_at": 1746622410.7972264}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 11.680191040039062, "logged_at": 1746622413.5211112}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 11.814792156219482, "logged_at": 1746622413.641167}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 13.044304847717285, "logged_at": 1746622414.8826118}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 13.479011297225952, "logged_at": 1746622415.3221872}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 14.861811399459839, "logged_at": 1746622416.7020545}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 15.325249910354614, "logged_at": 1746622417.1737666}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 15.611729145050049, "logged_at": 1746622417.458394}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.4825916290283203, "logged_at": 1746622451.9019961}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 2.448225736618042, "logged_at": 1746622452.870851}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 2.5452733039855957, "logged_at": 1746622452.9716713}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 2.6222786903381348, "logged_at": 1746622453.0510771}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 2.8594493865966797, "logged_at": 1746622453.2898688}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 2.9811840057373047, "logged_at": 1746622453.416111}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 3.2208144664764404, "logged_at": 1746622453.637756}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 3.300816535949707, "logged_at": 1746622453.7350695}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 3.397475004196167, "logged_at": 1746622453.828735}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 3.7933011054992676, "logged_at": 1746622454.2134573}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 4.03044319152832, "logged_at": 1746622454.4623308}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 4.494783878326416, "logged_at": 1746622454.930897}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 4.940012216567993, "logged_at": 1746622455.3731937}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 6.556114673614502, "logged_at": 1746622456.977219}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 6.581154108047485, "logged_at": 1746622457.0055244}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 6.652241468429565, "logged_at": 1746622457.0773733}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 7.01737380027771, "logged_at": 1746622457.4468696}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 7.3051629066467285, "logged_at": 1746622457.7406888}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 8.028200387954712, "logged_at": 1746622458.465376}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 8.53834342956543, "logged_at": 1746622458.9708104}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 9.221313238143921, "logged_at": 1746622459.6600401}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 10.376845598220825, "logged_at": 1746622460.8182204}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 10.585711479187012, "logged_at": 1746622461.0259252}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 13.150266408920288, "logged_at": 1746622463.5908825}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.9487581253051758, "logged_at": 1746622504.7093658}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.0074670314788818, "logged_at": 1746622504.7666018}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 1.0636498928070068, "logged_at": 1746622504.8252025}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 1.101771354675293, "logged_at": 1746622504.8739989}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 1.220247745513916, "logged_at": 1746622504.9836009}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 1.356759786605835, "logged_at": 1746622505.1268146}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 1.347891092300415, "logged_at": 1746622505.130292}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 1.3701748847961426, "logged_at": 1746622505.1348047}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 1.3972277641296387, "logged_at": 1746622505.1742456}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 1.526505470275879, "logged_at": 1746622505.2943387}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 1.6436586380004883, "logged_at": 1746622505.423468}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 1.6904182434082031, "logged_at": 1746622505.4695652}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 1.7242493629455566, "logged_at": 1746622505.4978695}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.7527663707733154, "logged_at": 1746622505.5286162}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 1.8510100841522217, "logged_at": 1746622505.6163356}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 1.849726676940918, "logged_at": 1746622505.6188028}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.8574714660644531, "logged_at": 1746622505.623624}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 1.8578753471374512, "logged_at": 1746622505.6294105}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 1.9271917343139648, "logged_at": 1746622505.7105258}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 1.9715454578399658, "logged_at": 1746622505.7468681}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 2.425271987915039, "logged_at": 1746622506.1997619}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 3.496629238128662, "logged_at": 1746622507.2749476}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 4.5534348487854, "logged_at": 1746622508.335206}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 4.768221616744995, "logged_at": 1746622508.5492527}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 5.350796222686768, "logged_at": 1746623199.1639495}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 1.4103410243988037, "logged_at": 1746623200.5745146}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 10.39779019355774, "logged_at": 1746623204.2315767}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 2.3717894554138184, "logged_at": 1746623206.6038744}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 1.8053171634674072, "logged_at": 1746623233.7510254}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 1.931565284729004, "logged_at": 1746623233.87519}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 2.8079071044921875, "logged_at": 1746623259.8515887}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 3.9268884658813477, "logged_at": 1746623260.9731183}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 1.7684223651885986, "logged_at": 1746623287.089251}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 2.942072629928589, "logged_at": 1746623288.2648873}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 2.227459192276001, "logged_at": 1746623315.9447281}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 4.41527533531189, "logged_at": 1746623318.1311357}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 1.9031801223754883, "logged_at": 1746623356.9067395}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 2.444709300994873, "logged_at": 1746623357.4505074}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 0.6732790470123291, "logged_at": 1746623397.3495595}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.7377779483795166, "logged_at": 1746623397.41639}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.7626433372497559, "logged_at": 1746623397.4360566}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 0.7730979919433594, "logged_at": 1746623397.524161}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 0.8443999290466309, "logged_at": 1746623397.5253015}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 0.8130834102630615, "logged_at": 1746623397.562142}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 0.8400390148162842, "logged_at": 1746623397.6000044}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 0.8395395278930664, "logged_at": 1746623397.601852}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.890615701675415, "logged_at": 1746623397.6386263}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 0.973747730255127, "logged_at": 1746623397.7255902}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.1280145645141602, "logged_at": 1746623397.8079188}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 1.056483268737793, "logged_at": 1746623397.8196619}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.3176212310791016, "logged_at": 1746623398.0764756}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 1.4468967914581299, "logged_at": 1746623398.2026985}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 1.5307130813598633, "logged_at": 1746623398.2924194}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 1.5484907627105713, "logged_at": 1746623398.3188765}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 1.5702369213104248, "logged_at": 1746623398.3204079}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 1.6396872997283936, "logged_at": 1746623398.3965447}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 1.6891214847564697, "logged_at": 1746623398.453215}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 1.7646534442901611, "logged_at": 1746623398.51756}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 1.800133466720581, "logged_at": 1746623398.5654511}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 1.806386947631836, "logged_at": 1746623398.5726194}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 2.1304378509521484, "logged_at": 1746623398.8979197}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 2.4026899337768555, "logged_at": 1746623399.1742675}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 2.6229007244110107, "logged_at": 1746623399.3913398}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 2.8861255645751953, "logged_at": 1746623399.6554143}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.29015159606933594, "logged_at": 1746623441.525717}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 0.295504093170166, "logged_at": 1746623441.5348155}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 0.3104853630065918, "logged_at": 1746623441.5578613}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 0.3163492679595947, "logged_at": 1746623441.5627844}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 0.32416868209838867, "logged_at": 1746623441.566432}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.32532429695129395, "logged_at": 1746623441.5667257}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 0.33318185806274414, "logged_at": 1746623441.571006}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 0.32535839080810547, "logged_at": 1746623441.5713115}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 0.33237314224243164, "logged_at": 1746623441.5751748}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 0.3357250690460205, "logged_at": 1746623441.5791416}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.3473362922668457, "logged_at": 1746623441.583882}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 0.3400304317474365, "logged_at": 1746623441.5880115}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 0.3501627445220947, "logged_at": 1746623441.5996015}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 0.3711583614349365, "logged_at": 1746623441.6095245}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 0.38452887535095215, "logged_at": 1746623441.6286528}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 0.37703442573547363, "logged_at": 1746623441.634558}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 0.3919546604156494, "logged_at": 1746623441.644701}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 0.4020042419433594, "logged_at": 1746623441.6557848}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 0.407301664352417, "logged_at": 1746623441.6580782}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 0.4058406352996826, "logged_at": 1746623441.661798}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 0.4156949520111084, "logged_at": 1746623441.6703138}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 0.4167666435241699, "logged_at": 1746623441.6760232}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 0.4215881824493408, "logged_at": 1746623441.6797159}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 0.4411036968231201, "logged_at": 1746623441.6891332}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 0.46180057525634766, "logged_at": 1746623441.7134957}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 0.7090156078338623, "logged_at": 1746623441.9659185}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.6508958339691162, "logged_at": 1746623477.9369245}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 0.682767391204834, "logged_at": 1746623477.9704285}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 0.7470951080322266, "logged_at": 1746623478.0371547}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.8743839263916016, "logged_at": 1746623478.1558673}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 0.9087560176849365, "logged_at": 1746623478.1915905}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 1.150869607925415, "logged_at": 1746623478.4217656}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 1.1558949947357178, "logged_at": 1746623478.4319007}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 1.2140393257141113, "logged_at": 1746623478.4965637}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.2311677932739258, "logged_at": 1746623478.5142765}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 1.3439486026763916, "logged_at": 1746623478.649031}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.3552813529968262, "logged_at": 1746623478.6617517}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 1.625962734222412, "logged_at": 1746623478.9195027}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 1.7370245456695557, "logged_at": 1746623479.0254955}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 2.068854331970215, "logged_at": 1746623479.364948}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 2.181164026260376, "logged_at": 1746623479.4846117}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 2.688962697982788, "logged_at": 1746623479.9837985}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 3.2840538024902344, "logged_at": 1746623480.585003}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 3.412036180496216, "logged_at": 1746623480.7045221}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 3.4975497722625732, "logged_at": 1746623480.7893872}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 5.192452669143677, "logged_at": 1746623482.4951434}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 5.409811735153198, "logged_at": 1746623482.7193944}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 6.141840219497681, "logged_at": 1746623483.4399056}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 7.906850576400757, "logged_at": 1746623485.2057729}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 10.60196590423584, "logged_at": 1746623487.9080331}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 23.02617907524109, "logged_at": 1746623500.328635}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 23.368521451950073, "logged_at": 1746623500.6773612}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 0.27501583099365234, "logged_at": 1746623549.1694238}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 0.45943450927734375, "logged_at": 1746623549.3423913}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 0.4557497501373291, "logged_at": 1746623549.3598733}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 0.4583101272583008, "logged_at": 1746623549.3608034}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 0.45636677742004395, "logged_at": 1746623549.3611975}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 0.4570174217224121, "logged_at": 1746623549.361415}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 0.47704434394836426, "logged_at": 1746623549.3618057}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 0.47853946685791016, "logged_at": 1746623549.3620803}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 0.4609544277191162, "logged_at": 1746623549.3632212}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.4806382656097412, "logged_at": 1746623549.363633}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 0.46210384368896484, "logged_at": 1746623549.3639593}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 0.4722318649291992, "logged_at": 1746623549.3644545}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 0.45597028732299805, "logged_at": 1746623549.3646896}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 0.4687495231628418, "logged_at": 1746623549.3648877}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 0.4687178134918213, "logged_at": 1746623549.371634}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.7587175369262695, "logged_at": 1746623549.6495254}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 0.7447433471679688, "logged_at": 1746623549.6546426}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 0.7479848861694336, "logged_at": 1746623549.6549332}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 0.756213903427124, "logged_at": 1746623549.6550722}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.7696490287780762, "logged_at": 1746623549.6552918}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 0.7551848888397217, "logged_at": 1746623549.655533}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 0.7638652324676514, "logged_at": 1746623549.655717}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 0.7684547901153564, "logged_at": 1746623549.655864}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 0.7504739761352539, "logged_at": 1746623549.6560092}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 0.7584836483001709, "logged_at": 1746623549.6562576}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 0.7531070709228516, "logged_at": 1746623549.6564722}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.9940891265869141, "logged_at": 1746623593.9826539}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 1.0640690326690674, "logged_at": 1746623594.065782}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 1.052647590637207, "logged_at": 1746623594.0807066}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 1.2579617500305176, "logged_at": 1746623594.2631245}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.3260319232940674, "logged_at": 1746623594.3240252}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 1.3653419017791748, "logged_at": 1746623594.3904753}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 1.4066295623779297, "logged_at": 1746623594.4154646}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 1.4324321746826172, "logged_at": 1746623594.4241724}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 1.5105605125427246, "logged_at": 1746623594.527734}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 1.5480051040649414, "logged_at": 1746623594.5384343}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 1.5331203937530518, "logged_at": 1746623594.5553384}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.8674230575561523, "logged_at": 1746623594.8825955}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 1.895268440246582, "logged_at": 1746623594.9154966}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 2.3899571895599365, "logged_at": 1746623595.4039567}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 2.7357473373413086, "logged_at": 1746623595.7422438}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 4.034449100494385, "logged_at": 1746623597.0786712}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 12.02936053276062, "logged_at": 1746623605.062049}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 13.268214225769043, "logged_at": 1746623606.2672696}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 13.378088235855103, "logged_at": 1746623606.3898299}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 13.649737358093262, "logged_at": 1746623606.6451511}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 14.722940683364868, "logged_at": 1746623607.7389932}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 17.12619924545288, "logged_at": 1746623610.1510305}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 18.31241226196289, "logged_at": 1746623611.3221977}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 19.582082748413086, "logged_at": 1746623612.6244378}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 25.657378673553467, "logged_at": 1746623618.6972933}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 31.432442903518677, "logged_at": 1746623624.4616363}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 8.29204797744751, "logged_at": 1746623686.2653787}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 13.359870195388794, "logged_at": 1746623691.3422852}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 14.957603931427002, "logged_at": 1746623692.9320953}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 24.865898370742798, "logged_at": 1746623702.843023}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 25.779369354248047, "logged_at": 1746623703.7807102}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 25.960960865020752, "logged_at": 1746623703.947408}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 26.16535758972168, "logged_at": 1746623704.1527815}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 26.19295859336853, "logged_at": 1746623704.1729596}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 26.35567593574524, "logged_at": 1746623704.3464084}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 33.49765205383301, "logged_at": 1746623711.4730198}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 33.70428967475891, "logged_at": 1746623711.685958}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 34.892558574676514, "logged_at": 1746623712.8825693}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 40.39991593360901, "logged_at": 1746623718.3879979}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 51.30831837654114, "logged_at": 1746623729.2936015}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 57.130619525909424, "logged_at": 1746623735.1291432}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 60.24059772491455, "logged_at": 1746623738.2168133}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 69.36782360076904, "logged_at": 1746623747.3628867}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 75.51495742797852, "logged_at": 1746623753.5182528}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 82.9183292388916, "logged_at": 1746623760.9127352}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 86.06800246238708, "logged_at": 1746623764.0682573}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 103.81918215751648, "logged_at": 1746623781.8162596}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 107.97348237037659, "logged_at": 1746623785.9568114}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 111.57923698425293, "logged_at": 1746623789.5715604}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 112.07296705245972, "logged_at": 1746623790.052275}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 112.65638852119446, "logged_at": 1746623790.652549}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 140.23434400558472, "logged_at": 1746623818.2312734}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 4.404778480529785, "logged_at": 1746623864.3300242}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 6.15758204460144, "logged_at": 1746623866.087183}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 7.052466630935669, "logged_at": 1746623866.990168}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 7.170103549957275, "logged_at": 1746623867.0865424}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 7.6799726486206055, "logged_at": 1746623867.6235597}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 8.388053178787231, "logged_at": 1746623868.3157387}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 8.876728534698486, "logged_at": 1746623868.8176045}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 9.226129055023193, "logged_at": 1746623869.1549451}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 10.073099613189697, "logged_at": 1746623870.0073884}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 11.169472932815552, "logged_at": 1746623871.1079836}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 13.06198525428772, "logged_at": 1746623872.9852653}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 13.324275732040405, "logged_at": 1746623873.2460265}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 13.424763679504395, "logged_at": 1746623873.3649614}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 14.229040622711182, "logged_at": 1746623874.1735027}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 14.274447441101074, "logged_at": 1746623874.210291}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 14.821083068847656, "logged_at": 1746623874.754381}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 15.014029741287231, "logged_at": 1746623874.948114}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 16.431772470474243, "logged_at": 1746623876.3623066}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 17.21819281578064, "logged_at": 1746623877.1374428}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 17.653177976608276, "logged_at": 1746623877.589575}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 4.473982334136963, "logged_at": 1746623877.7203207}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 18.835034608840942, "logged_at": 1746623878.7745872}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 20.69656014442444, "logged_at": 1746623880.6391273}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 23.54280185699463, "logged_at": 1746623883.4882107}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 25.796979904174805, "logged_at": 1746623885.7176077}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 37.31278347969055, "logged_at": 1746623897.2443025}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 7.200355768203735, "logged_at": 1746623904.444932}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 51.92246079444885, "logged_at": 1746623911.849477}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 22.57827877998352, "logged_at": 1746623934.428251}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 3.187012195587158, "logged_at": 1746623961.0129693}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 5.407377004623413, "logged_at": 1746623963.2488713}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 6.587560176849365, "logged_at": 1746623964.4198272}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 6.881090402603149, "logged_at": 1746623964.7181146}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 7.2405784130096436, "logged_at": 1746623965.0709918}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 7.419631004333496, "logged_at": 1746623965.25348}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 7.564213514328003, "logged_at": 1746623965.4078252}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 7.955502271652222, "logged_at": 1746623965.7843246}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 8.148558378219604, "logged_at": 1746623966.008458}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 8.961391687393188, "logged_at": 1746623966.8081203}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 9.44586992263794, "logged_at": 1746623967.2686293}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 9.798709630966187, "logged_at": 1746623967.6472223}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 9.844460248947144, "logged_at": 1746623967.6889424}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 11.612791061401367, "logged_at": 1746623969.4605203}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 11.793197870254517, "logged_at": 1746623969.6285625}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 12.556821584701538, "logged_at": 1746623970.4132743}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 13.317188739776611, "logged_at": 1746623971.1600192}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 14.077468395233154, "logged_at": 1746623971.9283988}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 14.132635354995728, "logged_at": 1746623971.9837587}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 21.653318881988525, "logged_at": 1746623979.4921193}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 23.847235202789307, "logged_at": 1746623981.6802518}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 26.152228593826294, "logged_at": 1746623984.0023298}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 27.613794088363647, "logged_at": 1746623985.4590023}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 37.022576570510864, "logged_at": 1746623994.8762753}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 45.367653131484985, "logged_at": 1746624003.2226062}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 57.01800894737244, "logged_at": 1746624014.8710697}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 1.0887975692749023, "logged_at": 1746624053.8958566}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 1.248314619064331, "logged_at": 1746624054.053307}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 1.346083164215088, "logged_at": 1746624054.164574}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 1.4231173992156982, "logged_at": 1746624054.2381604}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.4352335929870605, "logged_at": 1746624054.2443929}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 1.6225807666778564, "logged_at": 1746624054.4433613}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.6480913162231445, "logged_at": 1746624054.4581048}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 1.6548609733581543, "logged_at": 1746624054.4811912}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 1.6982223987579346, "logged_at": 1746624054.512174}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 1.7497694492340088, "logged_at": 1746624054.5714705}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 1.7588415145874023, "logged_at": 1746624054.575145}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 1.786623239517212, "logged_at": 1746624054.5982513}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 1.9158542156219482, "logged_at": 1746624054.733333}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 2.042177677154541, "logged_at": 1746624054.8747072}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 2.0761311054229736, "logged_at": 1746624054.9068928}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 2.1920182704925537, "logged_at": 1746624055.016446}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 2.245920181274414, "logged_at": 1746624055.068827}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 2.316542148590088, "logged_at": 1746624055.1544828}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 2.7443859577178955, "logged_at": 1746624055.579758}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 3.323817729949951, "logged_at": 1746624063.6771235}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 4.379392862319946, "logged_at": 1746624065.741464}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 2.481443166732788, "logged_at": 1746624065.8492599}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 4.116353511810303, "logged_at": 1746624067.5016556}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 2.0071511268615723, "logged_at": 1746624067.8942888}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 2.2444005012512207, "logged_at": 1746624069.9699986}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 3.5260136127471924, "logged_at": 1746624410.491351}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 3.741084575653076, "logged_at": 1746624410.7055204}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 3.758758306503296, "logged_at": 1746624410.727378}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 3.86956524848938, "logged_at": 1746624410.8368852}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 0.8286519050598145, "logged_at": 1746624411.32037}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 0.9200222492218018, "logged_at": 1746624411.6261337}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.9937078952789307, "logged_at": 1746624411.7215343}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 5.80267858505249, "logged_at": 1746624412.7825742}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 3.0021872520446777, "logged_at": 1746624413.8393333}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 1.3619413375854492, "logged_at": 1746624414.144894}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 14.410219192504883, "logged_at": 1746624421.3835986}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 14.438004493713379, "logged_at": 1746624421.413309}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 0.8425941467285156, "logged_at": 1746624422.2265215}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.5113439559936523, "logged_at": 1746624422.9249873}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 16.152819633483887, "logged_at": 1746624423.1338973}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 16.201066493988037, "logged_at": 1746624423.1706254}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 0.9049186706542969, "logged_at": 1746624424.0758097}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 1.0899255275726318, "logged_at": 1746624424.2240944}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 0.7007756233215332, "logged_at": 1746624446.509383}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 0.7312924861907959, "logged_at": 1746624446.5388405}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 0.7653541564941406, "logged_at": 1746624446.5845616}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 0.7805824279785156, "logged_at": 1746624446.591879}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 0.8241069316864014, "logged_at": 1746624446.6364894}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.840939998626709, "logged_at": 1746624446.654093}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 0.9015378952026367, "logged_at": 1746624446.7162309}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 1.3209233283996582, "logged_at": 1746624447.1488972}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 1.338510513305664, "logged_at": 1746624447.1653695}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.0001611709594727, "logged_at": 1746624467.646278}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 1.0904455184936523, "logged_at": 1746624467.729425}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.1340038776397705, "logged_at": 1746624467.7814202}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 1.2130560874938965, "logged_at": 1746624467.8532825}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.3197970390319824, "logged_at": 1746624467.9648023}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 1.5786635875701904, "logged_at": 1746624468.234104}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.780677318572998, "logged_at": 1746624468.430491}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 2.390193223953247, "logged_at": 1746624469.0472164}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 5.080058813095093, "logged_at": 1746624471.7179477}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 1.2555313110351562, "logged_at": 1746627096.7374687}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.3002052307128906, "logged_at": 1746627096.7948961}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.3229072093963623, "logged_at": 1746627096.8219385}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.418797492980957, "logged_at": 1746627096.9373972}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.7157371044158936, "logged_at": 1746627097.1950998}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 1.8629286289215088, "logged_at": 1746627097.4025621}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 2.299229621887207, "logged_at": 1746627097.796385}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 2.8103458881378174, "logged_at": 1746627098.3130596}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 3.5246338844299316, "logged_at": 1746627099.0547416}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 1.7213389873504639, "logged_at": 1746627133.848321}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 2.5874826908111572, "logged_at": 1746627134.7122438}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 2.7494637966156006, "logged_at": 1746627134.917466}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 3.534625291824341, "logged_at": 1746627135.6840692}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 3.9638185501098633, "logged_at": 1746627136.0930927}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 5.378251075744629, "logged_at": 1746627137.541549}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 11.065578937530518, "logged_at": 1746627143.197186}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 11.281504392623901, "logged_at": 1746627143.4254465}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 21.80890655517578, "logged_at": 1746627153.9644883}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.7760870456695557, "logged_at": 1746627163.2092614}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 0.9092652797698975, "logged_at": 1746627163.2651706}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 0.8945577144622803, "logged_at": 1746627163.3287523}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 0.9284322261810303, "logged_at": 1746627163.3607886}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.086456298828125, "logged_at": 1746627163.4378939}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 1.1644868850708008, "logged_at": 1746627163.5189734}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 1.185974359512329, "logged_at": 1746627163.6301854}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.2531213760375977, "logged_at": 1746627163.6987379}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 1.3721578121185303, "logged_at": 1746627163.820298}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 1.0761139392852783, "logged_at": 1746627201.122085}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 1.2010116577148438, "logged_at": 1746627201.2459252}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.2922344207763672, "logged_at": 1746627201.3411534}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.3132548332214355, "logged_at": 1746627201.35705}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 1.3227598667144775, "logged_at": 1746627201.3728569}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.3659932613372803, "logged_at": 1746627201.4184592}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 1.3959448337554932, "logged_at": 1746627201.453619}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.426067590713501, "logged_at": 1746627201.4761446}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 1.627448320388794, "logged_at": 1746627201.6860182}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 0.2702159881591797, "logged_at": 1746627226.8056781}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.2713770866394043, "logged_at": 1746627226.8089707}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 0.27560901641845703, "logged_at": 1746627226.8094065}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 0.27033185958862305, "logged_at": 1746627226.8106802}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 0.27907323837280273, "logged_at": 1746627226.8132043}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 0.2902979850769043, "logged_at": 1746627226.8289838}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 0.3008561134338379, "logged_at": 1746627226.8444798}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 0.7590208053588867, "logged_at": 1746627227.3083081}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 0.7724547386169434, "logged_at": 1746627227.3239117}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 0.9049506187438965, "logged_at": 1746627255.7492042}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.188530683517456, "logged_at": 1746627256.0341852}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.333960771560669, "logged_at": 1746627256.1764507}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 1.6790380477905273, "logged_at": 1746627256.529971}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.6918621063232422, "logged_at": 1746627256.5403376}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.9746935367584229, "logged_at": 1746627256.8292744}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 2.270709991455078, "logged_at": 1746627257.118795}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 2.3068859577178955, "logged_at": 1746627257.170905}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 3.1317687034606934, "logged_at": 1746627257.9940498}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 0.2322521209716797, "logged_at": 1746627282.5849102}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 0.2343156337738037, "logged_at": 1746627282.5884824}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 0.28935670852661133, "logged_at": 1746627282.6271079}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 0.2901318073272705, "logged_at": 1746627282.6481283}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.2938687801361084, "logged_at": 1746627282.6504056}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 0.2921464443206787, "logged_at": 1746627282.6510592}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 0.2955625057220459, "logged_at": 1746627282.6515129}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 0.2880544662475586, "logged_at": 1746627282.6514404}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 0.29915285110473633, "logged_at": 1746627282.6518435}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.2777690887451172, "logged_at": 1746627317.9884477}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.391049861907959, "logged_at": 1746627318.103073}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.584038496017456, "logged_at": 1746627318.2933195}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 1.8615078926086426, "logged_at": 1746627318.5740924}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 1.902726173400879, "logged_at": 1746627318.6247838}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 2.2890048027038574, "logged_at": 1746627319.0068176}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 3.1403279304504395, "logged_at": 1746627319.86604}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 21.131405115127563, "logged_at": 1746627337.846481}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 21.20133066177368, "logged_at": 1746627337.914767}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 5.6627349853515625, "logged_at": 1746627359.7668402}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 12.798206090927124, "logged_at": 1746627366.914253}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 14.056083917617798, "logged_at": 1746627368.1609797}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 20.33188247680664, "logged_at": 1746627374.4381166}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 25.615925073623657, "logged_at": 1746627379.7249627}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 27.777429342269897, "logged_at": 1746627381.8946}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 31.23475956916809, "logged_at": 1746627385.3429239}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 38.35818791389465, "logged_at": 1746627392.4656138}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 94.98531603813171, "logged_at": 1746627449.0971868}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 7.254799842834473, "logged_at": 1746627474.6788063}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 7.483572483062744, "logged_at": 1746627474.9102647}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 7.884163856506348, "logged_at": 1746627475.3088043}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 8.700380802154541, "logged_at": 1746627476.123336}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 12.30085039138794, "logged_at": 1746627479.7266645}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 16.8766348361969, "logged_at": 1746627484.3106754}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 18.86102056503296, "logged_at": 1746627486.288581}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 22.152266025543213, "logged_at": 1746627489.5874753}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 29.239161491394043, "logged_at": 1746627496.6692212}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 8.041518449783325, "logged_at": 1746627519.3200629}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 8.082664728164673, "logged_at": 1746627519.3473938}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 8.710585117340088, "logged_at": 1746627519.9800196}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 9.18350887298584, "logged_at": 1746627520.460514}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 13.741151332855225, "logged_at": 1746627525.0121365}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 13.934796810150146, "logged_at": 1746627525.208381}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 15.653488397598267, "logged_at": 1746627526.920389}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 15.675377368927002, "logged_at": 1746627526.943208}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 16.30670189857483, "logged_at": 1746627527.588628}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.309053897857666, "logged_at": 1746627556.3117676}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 1.4026057720184326, "logged_at": 1746627556.409537}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.4182872772216797, "logged_at": 1746627556.4218469}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 1.417834758758545, "logged_at": 1746627556.4234753}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.5243849754333496, "logged_at": 1746627556.5260797}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 1.9956541061401367, "logged_at": 1746627557.0129669}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 3.3142242431640625, "logged_at": 1746627558.3149374}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 3.4912290573120117, "logged_at": 1746627558.504913}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 3.577695369720459, "logged_at": 1746627558.5897403}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 2.3618853092193604, "logged_at": 1746627608.4252152}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.4578864574432373, "logged_at": 1746627634.2082603}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.6359868049621582, "logged_at": 1746627634.4014316}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 0.6996784210205078, "logged_at": 1746627634.4908786}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 0.7760283946990967, "logged_at": 1746627634.555247}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 0.8120951652526855, "logged_at": 1746627634.5674508}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 0.8465750217437744, "logged_at": 1746627634.61082}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.8635995388031006, "logged_at": 1746627634.6215158}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 0.8705222606658936, "logged_at": 1746627634.642001}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 0.8834033012390137, "logged_at": 1746627634.6594853}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 0.9633891582489014, "logged_at": 1746627634.7246418}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.0411484241485596, "logged_at": 1746627634.7934704}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.0824275016784668, "logged_at": 1746627634.8487494}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 1.096219539642334, "logged_at": 1746627634.8700972}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 1.13801908493042, "logged_at": 1746627634.8856008}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 1.1579115390777588, "logged_at": 1746627634.946223}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.1801040172576904, "logged_at": 1746627634.9507868}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 1.3915729522705078, "logged_at": 1746627635.1764717}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.4182548522949219, "logged_at": 1746627635.205404}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 1.5067684650421143, "logged_at": 1746627635.2966921}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 1.5898480415344238, "logged_at": 1746627635.3841412}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 1.6631441116333008, "logged_at": 1746627635.4434614}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 2.0879247188568115, "logged_at": 1746627635.8735135}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 2.1381428241729736, "logged_at": 1746627635.9131546}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 2.1327388286590576, "logged_at": 1746627635.916212}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 2.3183608055114746, "logged_at": 1746627636.1074548}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 2.5749926567077637, "logged_at": 1746627636.352986}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 2.598034620285034, "logged_at": 1746627636.358412}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 3.458406925201416, "logged_at": 1746627637.251341}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 3.798963785171509, "logged_at": 1746627637.5896153}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 4.023287296295166, "logged_at": 1746627637.8204746}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 4.606319427490234, "logged_at": 1746627638.368677}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 4.703637599945068, "logged_at": 1746627638.4708383}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 5.976952314376831, "logged_at": 1746627639.733543}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 6.0153069496154785, "logged_at": 1746627639.784658}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 6.085646152496338, "logged_at": 1746627639.8624315}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.6578085422515869, "logged_at": 1746627682.3251703}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.7836813926696777, "logged_at": 1746627682.4681642}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 0.907707691192627, "logged_at": 1746627682.599074}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.9843580722808838, "logged_at": 1746627682.6483068}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 1.011906623840332, "logged_at": 1746627682.682795}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 1.014859676361084, "logged_at": 1746627682.6932795}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 1.0365471839904785, "logged_at": 1746627682.7168243}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 1.0851047039031982, "logged_at": 1746627682.7705715}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 1.1038610935211182, "logged_at": 1746627682.7762692}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 1.1998403072357178, "logged_at": 1746627682.8866196}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 1.2103776931762695, "logged_at": 1746627682.9049182}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 1.2148194313049316, "logged_at": 1746627682.9077492}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 1.2167072296142578, "logged_at": 1746627682.912345}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.3026983737945557, "logged_at": 1746627683.0098343}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 1.4108922481536865, "logged_at": 1746627683.1084101}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 1.538611650466919, "logged_at": 1746627683.2130044}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.6364052295684814, "logged_at": 1746627683.3057318}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.8014392852783203, "logged_at": 1746627683.477037}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.8806641101837158, "logged_at": 1746627683.5581172}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 1.872157335281372, "logged_at": 1746627683.562281}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 2.1009390354156494, "logged_at": 1746627683.805897}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 2.106811285018921, "logged_at": 1746627683.8130295}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 2.1509852409362793, "logged_at": 1746627683.8635304}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 2.3147683143615723, "logged_at": 1746627683.991202}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 2.3625576496124268, "logged_at": 1746627684.0665624}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 2.4803881645202637, "logged_at": 1746627684.1712918}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 2.591289520263672, "logged_at": 1746627684.3080404}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 2.682262897491455, "logged_at": 1746627684.3701572}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 2.835245370864868, "logged_at": 1746627684.5373044}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 3.785769462585449, "logged_at": 1746627685.4827518}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 3.8107306957244873, "logged_at": 1746627685.5131292}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 4.173439979553223, "logged_at": 1746627685.8834133}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 4.5760486125946045, "logged_at": 1746627686.2934098}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 8.114132404327393, "logged_at": 1746627689.8352315}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 8.99275541305542, "logged_at": 1746627690.7030838}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 0.6270179748535156, "logged_at": 1746627736.276114}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 0.6235556602478027, "logged_at": 1746627736.2775013}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.6390535831451416, "logged_at": 1746627736.2960544}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 0.6959669589996338, "logged_at": 1746627736.3517125}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.7045214176177979, "logged_at": 1746627736.3521514}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 0.686312198638916, "logged_at": 1746627736.3531287}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.7210323810577393, "logged_at": 1746627736.3711634}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 0.7431981563568115, "logged_at": 1746627736.4070704}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 0.7587378025054932, "logged_at": 1746627736.410621}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.7602095603942871, "logged_at": 1746627736.4256785}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 0.76920485496521, "logged_at": 1746627736.42694}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 0.7768099308013916, "logged_at": 1746627736.4381409}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 0.7883880138397217, "logged_at": 1746627736.4507186}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 0.8256924152374268, "logged_at": 1746627736.4960043}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 0.8419840335845947, "logged_at": 1746627736.51111}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 0.862532377243042, "logged_at": 1746627736.525743}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 0.9295063018798828, "logged_at": 1746627736.6007166}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 0.9702117443084717, "logged_at": 1746627736.6513457}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 1.0251140594482422, "logged_at": 1746627736.678338}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 0.994927167892456, "logged_at": 1746627736.6820285}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 1.0209105014801025, "logged_at": 1746627736.6935675}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 1.0273563861846924, "logged_at": 1746627736.706879}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 1.1004443168640137, "logged_at": 1746627736.7588785}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 1.0969245433807373, "logged_at": 1746627736.7713423}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 1.1071398258209229, "logged_at": 1746627736.7751906}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 1.13578462600708, "logged_at": 1746627736.8131185}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 1.1606297492980957, "logged_at": 1746627736.8429093}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 1.1835603713989258, "logged_at": 1746627736.8621616}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 1.2375366687774658, "logged_at": 1746627736.9138021}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 1.465649127960205, "logged_at": 1746627737.1250854}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 1.466059923171997, "logged_at": 1746627737.1515017}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 1.6483263969421387, "logged_at": 1746627737.3202496}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 1.9431555271148682, "logged_at": 1746627737.6293967}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 2.041675090789795, "logged_at": 1746627737.7259586}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 2.6030709743499756, "logged_at": 1746627738.2909868}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Create a custom feed", "duration": 0.2866842746734619, "logged_at": 1746627792.1724503}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Customize your profile", "duration": 0.26560091972351074, "logged_at": 1746627792.1897738}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Change Password", "duration": 0.2950565814971924, "logged_at": 1746627792.207902}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Appropriately Automated Worker-Centred Luxury Luddism", "duration": 0.424511194229126, "logged_at": 1746627792.3550336}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "2.3.6. Increasing Sophistication 2006-2012", "duration": 0.31642818450927734, "logged_at": 1746627795.4202616}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "I plan to split my code into the following discrete and organised modules:", "duration": 0.3103945255279541, "logged_at": 1746627795.5210376}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "It's rather difficult to write intentionally long and arduous sentences without reference; nevertheless, that is what I must endeavour to do, with growing irritation and growing difficulty of translation.", "duration": 0.8243668079376221, "logged_at": 1746627796.0791676}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Active Users Estimate", "duration": 0.20161080360412598, "logged_at": 1746627796.241615}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Figure 40: UI Mockup", "duration": 0.30635976791381836, "logged_at": 1746627796.415799}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "The system must provide secure authentication in order to restrict server access to authorised users.", "duration": 0.4355897903442383, "logged_at": 1746627797.5845253}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "To refine further:", "duration": 0.2142181396484375, "logged_at": 1746627798.2694328}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "This simple algorithm fulfills all requirements", "duration": 0.2188107967376709, "logged_at": 1746627799.3509743}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "I can learn a lot from how the firewall developed in this period", "duration": 0.5751330852508545, "logged_at": 1746627800.7714999}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "Some information about the ingress/egress network taps and periodic probing information sharing has been removed to make the text legible.", "duration": 0.533522367477417, "logged_at": 1746627801.7395022}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "oh, well that ratelimit lasted long", "duration": 0.3221287727355957, "logged_at": 1746627802.4509892}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "Oh what a piece of work is man; how noble in reason, how infinite in faculty, in form, in moving, how like an angel; in apprehension, how like a God!", "duration": 0.8553867340087891, "logged_at": 1746627803.1190636}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Privacy Policy Update", "duration": 0.23359179496765137, "logged_at": 1746627803.2888517}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "It's less about cost, more about latency. It already uses Claude and Llama for translating text that isn't yet visible (precisely because of cost), but they're just too slow. They'd probably be better if I hosted them myself, but I can't justify the massive fixed cost for that at the moment. I am curious though, would you be alright with higher latency if it meant the sentences included context?", "duration": 1.0788404941558838, "logged_at": 1746627806.628876}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "Only third of Britons want increase in defence spending, poll finds", "duration": 0.35244011878967285, "logged_at": 1746627808.573101}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "IDEA: Use AI (with tool use) to solve ciphers", "duration": 0.4766058921813965, "logged_at": 1746627810.6858892}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "The Noise Protocol is too high-level for my use case and may provide a fingerprinting vector. Cryptographic primitives originating from China are clearly undesirable due to the risk of backdoors.", "duration": 0.49431872367858887, "logged_at": 1746627815.986207}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Recent posts", "duration": 0.1655750274658203, "logged_at": 1746627817.3701398}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Character usage / range", "duration": 0.18516230583190918, "logged_at": 1746627818.4601927}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "That sounds like a recipe for a pantheon of destructive gods", "duration": 0.5012969970703125, "logged_at": 1746627820.7820334}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "We shall go on to the end, we shall fight in France, we shall fight on the seas and oceans, we shall fight with growing confidence and growing strength in the air, we shall defend our Island, whatever the cost may be, we shall fight on the beaches, we shall fight on the landing grounds, we shall fight in the fields and in the streets, we shall fight in the hills; we shall never surrender, and even if, which I do not for a moment believe, this Island or a large part of it were subjugated and starving, then our Empire beyond the seas, armed and guarded by the British Fleet, would carry on the struggle, until, in God\u2019s good time, the New World, with all its power and might, steps forth to the rescue and the liberation of the old.", "duration": 4.023065090179443, "logged_at": 1746627824.358588}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "In the end I realised it would take far too long, but I wanted to experiment with getting a bunch of AIs to yell at each other until they came to a consensus. I suspect you would have trouble balancing their RLHFd agreeableness (conceding too early) and the impression of prompting. If you told them to keep arguing the case and not be instantly agreeable, they would never stop. Maybe you could have them follow a template to make things a bit better.", "duration": 1.4678406715393066, "logged_at": 1746627826.8513393}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "To deal with hyperplanes in a 14-dimensional space, visualise a 3 dimensional space and say \"fourteen\" rather loudly.", "duration": 0.5046007633209229, "logged_at": 1746627828.0473375}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "In War and Peace and War, Peter Turchin uses his expertise in evolutionary biology to offer a bold new theory about the course of world history.", "duration": 0.48488712310791016, "logged_at": 1746627830.862009}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "Forecast on new AI tournament questions.", "duration": 0.560401439666748, "logged_at": 1746627831.837859}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "that means the one exosuit guy gets near constant exosuits - you can ralistically use them as much as possible, die, then get another, and keep doing this for 40 minutes", "duration": 0.8434751033782959, "logged_at": 1746627838.2833467}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "Code execution is a tool that allows the model to generate and run Python code.", "duration": 0.5917372703552246, "logged_at": 1746627839.9165587}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "What does that mean for your data?", "duration": 0.18524813652038574, "logged_at": 1746627843.5670853}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "paragraph", "sentence": "Either way, since the very first network censors have existed, there have been people trying to circumvent them. The techniques of censorship and circumvention have rapidly advanced in a continually evolving arms race. In 2006 the most advanced censorship apparatus at the time, the Great Firewall of China (GFW), could be bypassed by simply bilaterally ignoring the injected TCP connection resets [4]. By 2011 the GFW was actively probing suspected servers [5] and by 2021 it was analyzing the entropy of traffic to catch fully-encrypted protocols [6]. And permitted protocols aren\u2019t safe either: The GFW has analysed the exterior dataflow of SSH connections using machine learning (ML) to detect and block SSH tunnels since at least 2016 [7]", "duration": 3.7143795490264893, "logged_at": 1746627857.2981424}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "The woman said she quit her job because she felt \"unpopular\", partly because of a Star Wars personality test, and yet tried to also sue the company for \"unfair dismissal\".", "duration": 0.6422221660614014, "logged_at": 1746627871.3014388}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "For non methamticians, this is going to be tougher than the previous material, and you should expect to spend a long time studying the next two parts.", "duration": 0.5966804027557373, "logged_at": 1746627875.137617}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.2331380844116211, "logged_at": 1746627919.0975552}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.35025978088378906, "logged_at": 1746627919.107141}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.2537999153137207, "logged_at": 1746627919.109147}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.2694845199584961, "logged_at": 1746627919.1094244}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.28740429878234863, "logged_at": 1746627919.109649}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.3658430576324463, "logged_at": 1746627919.109894}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.3007814884185791, "logged_at": 1746627919.1100225}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.4164092540740967, "logged_at": 1746627919.1423707}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.40781068801879883, "logged_at": 1746627919.153029}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.7515959739685059, "logged_at": 1746627919.1551929}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.44736695289611816, "logged_at": 1746627919.2000432}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.7719979286193848, "logged_at": 1746627919.204968}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.4384284019470215, "logged_at": 1746627919.2659352}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.8850431442260742, "logged_at": 1746627919.3112574}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.45060157775878906, "logged_at": 1746627919.318829}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.9204254150390625, "logged_at": 1746627919.3636928}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.9515995979309082, "logged_at": 1746627919.3833642}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.8806822299957275, "logged_at": 1746627919.3883877}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.9791216850280762, "logged_at": 1746627919.3924625}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.8312227725982666, "logged_at": 1746627919.3942528}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.0426018238067627, "logged_at": 1746627919.4707046}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.7729847431182861, "logged_at": 1746627919.4708903}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.0559501647949219, "logged_at": 1746627919.5083108}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.8237643241882324, "logged_at": 1746627919.5173705}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.7914113998413086, "logged_at": 1746627919.5414336}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.9334559440612793, "logged_at": 1746627919.5641193}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.119370937347412, "logged_at": 1746627919.5715296}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.9712364673614502, "logged_at": 1746627919.6254237}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.0331318378448486, "logged_at": 1746627919.6278205}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 1.099677324295044, "logged_at": 1746627919.6669555}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.9853813648223877, "logged_at": 1746627919.675905}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 1.0660057067871094, "logged_at": 1746627919.6856499}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.1575238704681396, "logged_at": 1746627919.7563539}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.2303483486175537, "logged_at": 1746627919.836973}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.1713943481445312, "logged_at": 1746627919.8999603}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.3126869201660156, "logged_at": 1746627919.9342127}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.0466790199279785, "logged_at": 1746627919.936065}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.0401105880737305, "logged_at": 1746627919.941427}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.2400643825531006, "logged_at": 1746627919.9427938}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.063340187072754, "logged_at": 1746627919.947594}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.290034532546997, "logged_at": 1746627919.9742644}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.1625490188598633, "logged_at": 1746627919.9786673}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.1711835861206055, "logged_at": 1746627919.978799}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 1.3147962093353271, "logged_at": 1746627920.0051298}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.7817807197570801, "logged_at": 1746627920.1405318}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.8223729133605957, "logged_at": 1746627920.1779423}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.5870122909545898, "logged_at": 1746627920.1842332}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.8169145584106445, "logged_at": 1746627920.1865275}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 1.6567177772521973, "logged_at": 1746627920.1870975}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.585526943206787, "logged_at": 1746627920.203017}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.2272067070007324, "logged_at": 1746627920.270346}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.9721205234527588, "logged_at": 1746627920.2743487}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.0516855716705322, "logged_at": 1746627920.3334343}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 1.071028470993042, "logged_at": 1746627920.3937721}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 1.409822940826416, "logged_at": 1746627920.3939152}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 1.0523946285247803, "logged_at": 1746627920.4056287}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 1.213108777999878, "logged_at": 1746627920.4367208}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.2970213890075684, "logged_at": 1746627920.513382}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 1.770021677017212, "logged_at": 1746627920.5243275}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.3143408298492432, "logged_at": 1746627920.5391989}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.6386661529541016, "logged_at": 1746627920.6148927}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.8690228462219238, "logged_at": 1746627920.6198387}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 1.8787667751312256, "logged_at": 1746627920.637114}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.1746506690979004, "logged_at": 1746627920.6967413}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.446549892425537, "logged_at": 1746627920.739521}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 1.185394287109375, "logged_at": 1746627920.8329928}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.257230520248413, "logged_at": 1746627920.8808477}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 2.392362117767334, "logged_at": 1746627920.9109576}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.6469943523406982, "logged_at": 1746627920.9780834}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 1.2361681461334229, "logged_at": 1746627920.9839613}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 2.00994610786438, "logged_at": 1746627920.99495}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 2.7892253398895264, "logged_at": 1746627921.1883435}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.8834397792816162, "logged_at": 1746627921.2777636}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 3.019859552383423, "logged_at": 1746627921.3170733}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 2.6445791721343994, "logged_at": 1746627921.333576}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.8082973957061768, "logged_at": 1746627921.423628}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 3.2436389923095703, "logged_at": 1746627921.755876}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 3.4985191822052, "logged_at": 1746627921.8128219}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 3.586299180984497, "logged_at": 1746627921.8808925}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 3.980940580368042, "logged_at": 1746627922.2860343}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 2.4296586513519287, "logged_at": 1746627922.3517997}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 2.470741033554077, "logged_at": 1746627922.5369015}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 4.065847158432007, "logged_at": 1746627922.5977285}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 4.304410219192505, "logged_at": 1746627923.2249067}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 4.124971866607666, "logged_at": 1746627923.9659686}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 5.0705952644348145, "logged_at": 1746627924.027181}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 5.162291526794434, "logged_at": 1746627924.0739264}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 5.630640029907227, "logged_at": 1746627924.160292}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 5.471627712249756, "logged_at": 1746627924.434958}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 6.496118068695068, "logged_at": 1746627925.4090557}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 6.46940541267395, "logged_at": 1746627925.4225345}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 6.5881452560424805, "logged_at": 1746627925.4995856}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 6.768614053726196, "logged_at": 1746627925.717465}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 4.830642938613892, "logged_at": 1746627925.825834}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 7.179515361785889, "logged_at": 1746627926.070616}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 6.561982870101929, "logged_at": 1746627926.827581}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 2.6138949394226074, "logged_at": 1746627927.0493076}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 8.276283025741577, "logged_at": 1746627927.1662943}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 3.9480526447296143, "logged_at": 1746627927.173545}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 7.753150463104248, "logged_at": 1746627927.4305491}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 10.562524557113647, "logged_at": 1746627929.0911458}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 9.255704402923584, "logged_at": 1746627929.3462963}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 11.130764722824097, "logged_at": 1746627930.1028244}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 10.266202926635742, "logged_at": 1746627930.9038055}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 5.866660833358765, "logged_at": 1746627931.2760146}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 11.20705246925354, "logged_at": 1746627931.307171}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 13.37679648399353, "logged_at": 1746627933.9014132}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 10.347251415252686, "logged_at": 1746627934.4216745}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 14.378845691680908, "logged_at": 1746627934.4494562}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 16.958070039749146, "logged_at": 1746627935.757234}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 17.841932773590088, "logged_at": 1746627936.8289728}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 20.362973928451538, "logged_at": 1746627939.301001}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.4858980178833008, "logged_at": 1746627940.1191247}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.4995741844177246, "logged_at": 1746627940.1261039}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.6944997310638428, "logged_at": 1746627940.3220198}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 1.2692322731018066, "logged_at": 1746627940.900568}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.5673544406890869, "logged_at": 1746627940.9466317}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 22.15524983406067, "logged_at": 1746627940.9925091}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.7582380771636963, "logged_at": 1746627941.1387262}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.8064746856689453, "logged_at": 1746627941.188334}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.9115352630615234, "logged_at": 1746627941.2866442}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.6205010414123535, "logged_at": 1746627941.3228738}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.7106306552886963, "logged_at": 1746627941.3424134}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.7124221324920654, "logged_at": 1746627941.418374}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.7263600826263428, "logged_at": 1746627941.431404}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.741626501083374, "logged_at": 1746627941.4508526}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 1.0825996398925781, "logged_at": 1746627941.4561582}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.8852725028991699, "logged_at": 1746627941.5892463}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Installed Apps", "duration": 0.2594757080078125, "logged_at": 1746627941.6783662}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Terms of Service", "duration": 0.3778235912322998, "logged_at": 1746627941.7010841}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.6558883190155029, "logged_at": 1746627941.9428418}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.6984901428222656, "logged_at": 1746627942.1551085}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Community Bookmarks", "duration": 0.9631671905517578, "logged_at": 1746627942.394864}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "phrases_internet", "sentence": "Help and FAQ", "duration": 0.6373634338378906, "logged_at": 1746627948.299007}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 0.9398074150085449, "logged_at": 1746627949.5137672}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "Hover to translate back!", "duration": 32.55517864227295, "logged_at": 1746627951.3819935}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.2334291934967041, "logged_at": 1746628696.9469259}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 0.27112555503845215, "logged_at": 1746628696.9502258}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 0.23507952690124512, "logged_at": 1746628696.954955}
{"model_id": "DeepLDeepLDeepLNone", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 0.29526281356811523, "logged_at": 1746628696.9655197}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.20424771308898926, "logged_at": 1746628696.9811404}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 0.28609180450439453, "logged_at": 1746628697.0413804}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 0.2825915813446045, "logged_at": 1746628697.0415797}
{"model_id": "LingvanexLingvanexLingvanexNone", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 0.3238081932067871, "logged_at": 1746628697.047019}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.9777865409851074, "logged_at": 1746628697.2447126}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.9721415042877197, "logged_at": 1746628697.346547}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.1910443305969238, "logged_at": 1746628697.5776632}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.234259843826294, "logged_at": 1746628697.6935236}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.1632983684539795, "logged_at": 1746628697.7126584}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.3128330707550049, "logged_at": 1746628697.718665}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.2637572288513184, "logged_at": 1746628697.7188451}
{"model_id": "GPT 4oOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 1.376525640487671, "logged_at": 1746628697.7431915}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.2526209354400635, "logged_at": 1746628697.775962}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.5520226955413818, "logged_at": 1746628697.815966}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.326627492904663, "logged_at": 1746628697.844497}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.5077955722808838, "logged_at": 1746628697.8677256}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.4515125751495361, "logged_at": 1746628697.8824015}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.5014233589172363, "logged_at": 1746628697.9448786}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.3855502605438232, "logged_at": 1746628697.9499009}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.817246675491333, "logged_at": 1746628697.9809995}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.4791581630706787, "logged_at": 1746628698.031579}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 0.8858990669250488, "logged_at": 1746628698.0724044}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.5060713291168213, "logged_at": 1746628698.0817313}
{"model_id": "GPT 4.1OpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 1.7522926330566406, "logged_at": 1746628698.1739097}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 1.5041277408599854, "logged_at": 1746628698.189495}
{"model_id": "GPT 4.1 MiniOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 1.672795057296753, "logged_at": 1746628698.2330997}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.6295230388641357, "logged_at": 1746628698.2455153}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.8393173217773438, "logged_at": 1746628698.2498372}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 1.8144919872283936, "logged_at": 1746628698.3248327}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.404069423675537, "logged_at": 1746628698.362869}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.7493748664855957, "logged_at": 1746628698.4312215}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.4087839126586914, "logged_at": 1746628698.4943247}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.5847203731536865, "logged_at": 1746628698.499617}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 2.176666021347046, "logged_at": 1746628698.5453863}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.3921895027160645, "logged_at": 1746628698.5475402}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.7983720302581787, "logged_at": 1746628698.5632813}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 2.0859766006469727, "logged_at": 1746628698.6068606}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 2.4405436515808105, "logged_at": 1746628698.768497}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.8040530681610107, "logged_at": 1746628698.9533865}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 2.6478326320648193, "logged_at": 1746628699.0235417}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 2.237745761871338, "logged_at": 1746628699.0295005}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.2724769115447998, "logged_at": 1746628699.1047525}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.6598010063171387, "logged_at": 1746628699.1160626}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.4161698818206787, "logged_at": 1746628699.2335796}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.3153517246246338, "logged_at": 1746628699.2639112}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.4076151847839355, "logged_at": 1746628699.279855}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.855504035949707, "logged_at": 1746628699.355341}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 3.038898229598999, "logged_at": 1746628699.3914857}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.7264721393585205, "logged_at": 1746628699.4345882}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 2.77675724029541, "logged_at": 1746628699.454394}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 3.163994312286377, "logged_at": 1746628699.48485}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 2.7022716999053955, "logged_at": 1746628699.6120033}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 2.5764830112457275, "logged_at": 1746628699.6534367}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 3.443693161010742, "logged_at": 1746628699.8073783}
{"model_id": "Gemini 2.5 Flash Preview 04-17GoogleOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 1.584165096282959, "logged_at": 1746628699.8820825}
{"model_id": "Grok 3 BetaX AIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 2.1623833179473877, "logged_at": 1746628700.0095594}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 2.9815282821655273, "logged_at": 1746628700.0402274}
{"model_id": "Gemma 3 27bGoogleOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 3.5687856674194336, "logged_at": 1746628700.1238956}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 0.6032397747039795, "logged_at": 1746628700.2155445}
{"model_id": "Claude Sonnet 3.7 2025-02-19AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 2.3814125061035156, "logged_at": 1746628700.6964836}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 4.573309421539307, "logged_at": 1746628700.7208297}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 4.669642686843872, "logged_at": 1746628700.8327556}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 5.2008349895477295, "logged_at": 1746628701.347022}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 3.031942367553711, "logged_at": 1746628701.395503}
{"model_id": "LLama 4 MaverickMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 4.663363456726074, "logged_at": 1746628701.579429}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 3.6082754135131836, "logged_at": 1746628701.6530235}
{"model_id": "Nuenki HybridNuenkiNuenkiNone", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 6.135582447052002, "logged_at": 1746628702.3756409}
{"model_id": "Qwen 3 32B A22BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 5.390685319900513, "logged_at": 1746628702.5408769}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 5.917860984802246, "logged_at": 1746628702.8002353}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 3.3210361003875732, "logged_at": 1746628702.8063312}
{"model_id": "LLama 4 ScoutMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 1.2969257831573486, "logged_at": 1746628702.876847}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 6.500628709793091, "logged_at": 1746628703.3322592}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 6.833414316177368, "logged_at": 1746628703.675446}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 7.917703628540039, "logged_at": 1746628704.262083}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 7.5211944580078125, "logged_at": 1746628704.4131043}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 7.828609466552734, "logged_at": 1746628704.7131586}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 6.220819473266602, "logged_at": 1746628704.766588}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 8.131866931915283, "logged_at": 1746628704.97341}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 9.815085411071777, "logged_at": 1746628706.6934474}
{"model_id": "Claude Sonnet 3.5 2024-10-22AnthropicAnthropic0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 9.935188055038452, "logged_at": 1746628707.7765782}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 15.162132740020752, "logged_at": 1746628711.9809954}
{"model_id": "Qwen 3 30B A3BAlibabaOpenrouter0.0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 15.13827109336853, "logged_at": 1746628711.989452}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 20.026886463165283, "logged_at": 1746628716.843776}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.8212015628814697, "logged_at": 1746628723.5390086}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 1.2919702529907227, "logged_at": 1746628724.013488}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.1841058731079102, "logged_at": 1746628724.170111}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 1.7226626873016357, "logged_at": 1746628724.4497957}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.6022121906280518, "logged_at": 1746628724.777924}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 2.596292495727539, "logged_at": 1746628725.3164852}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 0.6710820198059082, "logged_at": 1746628725.4181478}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 0.7339541912078857, "logged_at": 1746628725.48254}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 2.6643967628479004, "logged_at": 1746628725.6563153}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 0.9268813133239746, "logged_at": 1746628725.6781511}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 2.877556085586548, "logged_at": 1746628725.8676088}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 0.5290279388427734, "logged_at": 1746628725.9474926}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 0.5420262813568115, "logged_at": 1746628726.0249944}
{"model_id": "Llama 3.3 70bMetaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 3.116372585296631, "logged_at": 1746628726.1104267}
{"model_id": "GPT 4.1 NanoOpenAIOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 1.4736144542694092, "logged_at": 1746628726.2189405}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 0.8054547309875488, "logged_at": 1746628726.4840462}
{"model_id": "Qwen 3 14BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 29.561908721923828, "logged_at": 1746628733.2377782}
{"model_id": "Mistral Small LatestMistralMistral0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 0.44883108139038086, "logged_at": 1746628733.749436}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 48.32645106315613, "logged_at": 1746628746.7579772}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 58.99173140525818, "logged_at": 1746628755.8405116}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 21.6811363697052, "logged_at": 1746628756.1044745}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "short_sentence", "sentence": "This performance is adequate for small webpages but scales poorly.", "duration": 57.913288593292236, "logged_at": 1746628756.4770198}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 67.13431596755981, "logged_at": 1746628766.1642666}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 74.52240252494812, "logged_at": 1746628771.3293958}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "long_sentence", "sentence": "All the instrumentation remained on the Javascript side. I was surprised by how fast the WASM calls were - I expected the FFI (Foreign Function Interface) overhead to limit the performance improvements.", "duration": 73.16008424758911, "logged_at": 1746628772.614829}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "In addition to querying every sentence in every webpage, Nuenki also extensively uses them in its sentence-difficulty estimation.", "duration": 42.707422971725464, "logged_at": 1746628775.254028}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 41.5082221031189, "logged_at": 1746628775.9266052}
{"model_id": "Qwen 3 32BAlibabaOpenrouter0", "sentence_cat": "medium_sentence", "sentence": "I can enjoy my online time guilt free, knowing I'm also learning a new language.", "duration": 50.61682415008545, "logged_at": 1746628783.1592245}
